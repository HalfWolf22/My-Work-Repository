{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\vucin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vucin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vucin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vucin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vucin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vucin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easydatascience as eds\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "vanilla_data = pd.read_csv('vanilla_data.csv')\n",
    "diff_team_data = pd.read_csv('diff_team_data.csv')\n",
    "diff_data = pd.read_csv('diff_data.csv')\n",
    "compact_data = pd.read_csv('compact_data.csv')\n",
    "compact_diff_data = pd.read_csv('compact_diff_data.csv')\n",
    "bool_team_data = pd.read_csv('bool_team_data.csv')\n",
    "\n",
    "data = {'vanilla': vanilla_data,\n",
    "        'diff_team': diff_team_data,\n",
    "        'diff': diff_data,\n",
    "        'compact': compact_data,\n",
    "        'compact_diff': compact_diff_data,\n",
    "        'bool': bool_team_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Data\n",
    "The first dataset I wanted to examine is with only boolean values. Since it is very simple, it has a lot of use cases:\n",
    "- It doesn't require much computational power so it can be used on any machine.\n",
    "- Since the data is simple, the model can't be too complicated either (easy to understand).\n",
    "- Can be good for some simple early predictions.\n",
    "<br><br>\n",
    "&emsp;Of course, everything that I mentioned above (as I will do with every dataset that I am going to examine) is prone to change and should not be held true until proven otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy: 0.9798\n"
     ]
    }
   ],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(data['bool'].iloc[:, 1:],\n",
    "                                     data['bool']['Blue_Won'], test_size=0.1)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('Cross Validation Accuracy:', round(accuracy_score(y_cv, lr.predict(X_cv)), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;My best guess is that the model is already saturated by similar features with a high correlation. Remember, our goal is not to predict the winner with the data of the game when the game has already been finished, but we want to see the probabilities during the game. So lets first simplify the model and then run an experiment/simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data accuracy: 0.9497\n",
      "\n",
      "Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_FirstBlood</th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstBaron</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstBaron</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>Blue_KDA</th>\n",
       "      <th>Blue_VisionScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue_FirstBlood  Blue_FirstTower  Blue_FirstInhib  Blue_FirstBaron  \\\n",
       "0              0.5              0.5              0.5              0.5   \n",
       "\n",
       "   Blue_FirstDragon  Blue_FirstHerald  Purp_FirstInhib  Purp_FirstBaron  \\\n",
       "0               0.5               0.5              0.5              0.5   \n",
       "\n",
       "   Purp_FirstHerald  Blue_KDA  Blue_VisionScore  \n",
       "0               0.5       0.5               0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.5213\n",
      "1: 0.4787\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "bool1 = data['bool'].iloc[:, :12]\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(bool1.iloc[:, 1:],\n",
    "                                         bool1['Blue_Won'], test_size=0.1)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X1_train, y1_train)\n",
    "\n",
    "print('New data accuracy:', round(accuracy_score(y1_test, lr.predict(X1_test)), 4))\n",
    "\n",
    "sample_data = pd.DataFrame(0.5, index=range(1), columns=bool1.columns[1:])\n",
    "\n",
    "def print_sample():\n",
    "    print('\\nSample Data:')\n",
    "    display(sample_data)\n",
    "    \n",
    "print_sample()\n",
    "\n",
    "def proba_byclass():\n",
    "    print('---------------------\\nProbability by class:')\n",
    "    for class_, proba in zip(lr.classes_, lr.predict_proba(sample_data)[0]):\n",
    "        print(str(class_)+':', round(proba, 4))\n",
    "    print('---------------------')\n",
    "        \n",
    "proba_byclass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;It is expected to see the default results as these since the purple time is slightly favored. Let's see how is this going to play out, __The Blue team gets the First Blood__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_FirstBlood</th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstBaron</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstBaron</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>Blue_KDA</th>\n",
       "      <th>Blue_VisionScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue_FirstBlood  Blue_FirstTower  Blue_FirstInhib  Blue_FirstBaron  \\\n",
       "0              1.0              0.5              0.5              0.5   \n",
       "\n",
       "   Blue_FirstDragon  Blue_FirstHerald  Purp_FirstInhib  Purp_FirstBaron  \\\n",
       "0               0.5               0.5              0.5              0.5   \n",
       "\n",
       "   Purp_FirstHerald  Blue_KDA  Blue_VisionScore  \n",
       "0               0.5       1.0               0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.108\n",
      "1: 0.892\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "sample_data.loc[0, 'Blue_KDA'] = 1\n",
    "sample_data.loc[0, 'Blue_FirstBlood'] = 1\n",
    "\n",
    "print_sample()\n",
    "proba_byclass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;This looks a bit oversaturated. The problem here is probably the KDA ratio since the model has been trained on the data from finished games and KDA biases the prediction heavily. We should have that in mind continuing from now on but for now, let's just train the same model but now only without that feature. We can also see that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Log. Reg. Coefficients:\n",
      "\n",
      "Blue_FirstBlood: -0.0954\n",
      "Blue_FirstTower: 0.5988\n",
      "Blue_FirstInhib: 1.6776\n",
      "Blue_FirstBaron: 0.4642\n",
      "Blue_FirstDragon: 0.5691\n",
      "Blue_FirstHerald: -0.0783\n",
      "Purp_FirstInhib: -1.377\n",
      "Purp_FirstBaron: -0.7607\n",
      "Purp_FirstHerald: -0.1586\n",
      "Blue_KDA: 4.4892\n",
      "Blue_VisionScore: 0.3464\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------\\nLog. Reg. Coefficients:\\n')\n",
    "for ftr, coef in zip(sample_data.columns, lr.coef_[0]):\n",
    "    print(ftr+':', np.round(coef, 4))\n",
    "print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9024 \n",
      "\n",
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.5325\n",
      "1: 0.4675\n",
      "---------------------\n",
      "\n",
      "Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_FirstBlood</th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstBaron</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstBaron</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>Blue_VisionScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue_FirstBlood  Blue_FirstTower  Blue_FirstInhib  Blue_FirstBaron  \\\n",
       "0              1.0              0.5              0.5              0.5   \n",
       "\n",
       "   Blue_FirstDragon  Blue_FirstHerald  Purp_FirstInhib  Purp_FirstBaron  \\\n",
       "0               0.5               0.5              0.5              0.5   \n",
       "\n",
       "   Purp_FirstHerald  Blue_VisionScore  \n",
       "0               0.5               0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.4973\n",
      "1: 0.5027\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# No KDA\n",
    "bool2 = data['bool'].iloc[:, :12].drop('Blue_KDA', axis=1)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(bool2.iloc[:, 1:],\n",
    "                                         bool1['Blue_Won'], test_size=0.1)\n",
    "lr.fit(X2_train, y2_train)\n",
    "print('Accuracy:', round(accuracy_score(y2_test, lr.predict(X2_test)), 4), '\\n')\n",
    "\n",
    "sample_data = pd.DataFrame(0.5, index=range(1), columns=bool2.columns[1:])\n",
    "\n",
    "proba_byclass()\n",
    "\n",
    "sample_data.loc[0, 'Blue_FirstBlood'] = 1\n",
    "\n",
    "print_sample()\n",
    "proba_byclass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Well, that looks much better! Even though the initial probability of the Blue team winning got a bit lower and I can't seem to be able to explain that right now, it has something to do with the KDA obviously but we are going to leave it for now.\n",
    "<br><br>\n",
    "&emsp;On the other side, if you've been paying attention, you might've noticed that Blue_FirstBlood (Blue_FirstHerald is also not very shiny) has a negative coefficient in the Logistic Regression model for some reason. I am not going to explore that into detail so let's just say for now that the model might not be right for the job or that the data doesn't contain enough information. \n",
    "<br><br>\n",
    "&emsp;With that said, __The Purple team uses its jungle vision pressure to take the first dragon but they are quickly countered by the Blue team taking the First Tower. The Blue team takes the First Herald also and they make even more pressure even though the Purple team has more map control through Vision. Blue team snowballs fast taking the first Inhibitor and eventually the First Baron too. By now they have naturally taken over the Vision and they end the game rather fast, by the 25-minute mark. GG!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Dragon taken by Purple.\n",
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.5863\n",
      "1: 0.4137\n",
      "---------------------\n",
      "\n",
      "First Tower taken by Blue.\n",
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.4763\n",
      "1: 0.5237\n",
      "---------------------\n",
      "\n",
      "First Herald taken by Blue.\n",
      "Purple controlls the Vision.\n",
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.6061\n",
      "1: 0.3939\n",
      "---------------------\n",
      "\n",
      "Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_FirstBlood</th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstBaron</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstBaron</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>Blue_VisionScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue_FirstBlood  Blue_FirstTower  Blue_FirstInhib  Blue_FirstBaron  \\\n",
       "0              1.0              1.0              0.5              0.5   \n",
       "\n",
       "   Blue_FirstDragon  Blue_FirstHerald  Purp_FirstInhib  Purp_FirstBaron  \\\n",
       "0               0.0               1.0              0.5              0.5   \n",
       "\n",
       "   Purp_FirstHerald  Blue_VisionScore  \n",
       "0               0.0               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First Inhib taken by Blue.\n",
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.1831\n",
      "1: 0.8169\n",
      "---------------------\n",
      "\n",
      "First Baron taken by Blue.\n",
      "Blue controlls the Vision.\n",
      "---------------------\n",
      "Probability by class:\n",
      "0: 0.0272\n",
      "1: 0.9728\n",
      "---------------------\n",
      "\n",
      "Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_FirstBlood</th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstBaron</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstBaron</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>Blue_VisionScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue_FirstBlood  Blue_FirstTower  Blue_FirstInhib  Blue_FirstBaron  \\\n",
       "0              1.0              1.0              1.0              1.0   \n",
       "\n",
       "   Blue_FirstDragon  Blue_FirstHerald  Purp_FirstInhib  Purp_FirstBaron  \\\n",
       "0               0.0               1.0              0.0              0.0   \n",
       "\n",
       "   Purp_FirstHerald  Blue_VisionScore  \n",
       "0               0.0               1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_data.loc[0, 'Blue_FirstDragon'] = 0\n",
    "print('First Dragon taken by Purple.')\n",
    "proba_byclass()\n",
    "\n",
    "sample_data.loc[0, 'Blue_FirstTower'] = 1\n",
    "print('\\nFirst Tower taken by Blue.')\n",
    "proba_byclass()\n",
    "\n",
    "sample_data.loc[0, 'Blue_FirstHerald'] = 1\n",
    "sample_data.loc[0, 'Purp_FirstHerald'] = 0\n",
    "sample_data.loc[0, 'Blue_VisionScore'] = 0\n",
    "print('\\nFirst Herald taken by Blue.')\n",
    "print('Purple controlls the Vision.')\n",
    "proba_byclass()\n",
    "print_sample()\n",
    "\n",
    "sample_data.loc[0, 'Blue_FirstInhib'] = 1\n",
    "sample_data.loc[0, 'Purp_FirstInhib'] = 0\n",
    "print('\\nFirst Inhib taken by Blue.')\n",
    "proba_byclass()\n",
    "\n",
    "sample_data.loc[0, 'Blue_FirstBaron'] = 1\n",
    "sample_data.loc[0, 'Purp_FirstBaron'] = 0\n",
    "sample_data.loc[0, 'Blue_VisionScore'] = 1\n",
    "print('\\nFirst Baron taken by Blue.')\n",
    "print('Blue controlls the Vision.')\n",
    "proba_byclass()\n",
    "print_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;The other binarized numeric value, Vision, has also taken its toll by having too much weight put on it. It is not the same if a team leads by 0.1 KDA vs, 5 KDA, the same goes for the Vision, we can't reduce it to just that. Besides that, the Bool Data gave us a good overview of how could the probabilities move during the game.\n",
    "<br><br>\n",
    "&emsp;Remember that even though we are training the model on discrete binary variables, our final goal is still to guess a probability __during__ the game and we have no way of evaluating that. So the model's performance during the final testing is going to be purely subjective and we can't do much about it but take care of training on the hard values and not to make the mistakes as it could be seen with the binarized KDA and Vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the roles and getting a new df\n",
    "data['vanilla'] = data['vanilla'][[i for i in data['vanilla'] if 'Role' not in i]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['vanilla'].iloc[:, 1:],\n",
    "                                     data['vanilla']['Blue_Won'], test_size=0.05)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(data['vanilla'].iloc[:, 1:],\n",
    "                                     data['vanilla']['Blue_Won'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.9494527721288838\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=50, max_depth=X_train.shape[1], n_jobs=-1)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print('r2 score:', r2_score(y_cv, xgb.predict(X_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Important features\n",
      "---------------------\n",
      "\n",
      "Blue_FirstInhib 0.017061\n",
      "Blue_KillsTower 0.06262\n",
      "Blue_KillsInhib 0.031262\n",
      "Blue_KillsBaron 0.002677\n",
      "Blue_KillsDragon 0.00216\n",
      "Purp_FirstBaron 0.004392\n",
      "Purp_FirstHerald 0.002182\n",
      "Purp_KillsTower 0.047521\n",
      "Purp_KillsInhib 0.052228\n",
      "Purp_KillsBaron 0.003899\n",
      "player1_LrgstKillSpree 0.002055\n",
      "player1_KillSprees 0.002369\n",
      "player3_TtlGold 0.002343\n",
      "player4_KDAratio 0.002424\n",
      "player4_LrgstTimeLiving 0.002016\n",
      "player6_KillSprees 0.002545\n",
      "player7_KillSprees 0.002875\n",
      "player8_TtlGold 0.002203\n",
      "player9_LrgstKillSpree 0.002338\n",
      "player10_TtlDmgChmp 0.002013\n",
      "Blue_KDAratio 0.445634\n",
      "Blue_KillSprees 0.002532\n",
      "Blue_LrgstTimeLiving 0.002496\n",
      "Blue_TtlGold 0.002589\n",
      "Purp_KDAratio 0.140699\n",
      "Purp_LrgstMultiKill 0.002791\n",
      "Purp_TtlGold 0.003018\n",
      "\n",
      "r2 score, only important features: 0.9508439802354283\n"
     ]
    }
   ],
   "source": [
    "def get_importances(cols, rf, threshold=0.002):\n",
    "    print('---------------------\\nImportant features\\n---------------------\\n')\n",
    "    important = []\n",
    "\n",
    "    for feature, importance in zip(cols, [round(i, 6) for i in rf.feature_importances_]):\n",
    "        if importance > threshold:\n",
    "            print(feature, importance)\n",
    "            important.append(feature)\n",
    "            \n",
    "    return important\n",
    "\n",
    "important = get_importances(X_train.columns, xgb)\n",
    "        \n",
    "imp_df_train, imp_df_cv = X_train[important], X_cv[important]\n",
    "\n",
    "xgb_imp = XGBClassifier(n_estimators=50, max_depth=imp_df_train.shape[1], n_jobs=-1)\n",
    "xgb_imp.fit(imp_df_train, y_train)\n",
    "print('\\nr2 score, only important features:', r2_score(y_cv, xgb_imp.predict(imp_df_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score, not important features: 0.8687627019493038\n"
     ]
    }
   ],
   "source": [
    "not_imp_train, not_imp_cv = X_train[[i for i in X_train.columns if i not in important]], X_cv[[i for i in X_cv.columns if i not in important]]\n",
    "    \n",
    "xgb_imp = XGBClassifier(n_estimators=50, max_depth=imp_df_train.shape[1], n_jobs=-1)\n",
    "xgb_imp.fit(not_imp_train, y_train)\n",
    "print('r2 score, not important features:', r2_score(y_cv, xgb_imp.predict(not_imp_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Are leftover features important?\n",
      "---------------------\n",
      "\n",
      "Blue_FirstBaron 0.005771\n",
      "Purp_FirstInhib 0.708678\n",
      "Purp_KillsDragon 0.006138\n",
      "player1_KDAratio 0.005317\n",
      "player2_KDAratio 0.005079\n",
      "player3_KDAratio 0.007132\n",
      "player5_KDAratio 0.009173\n",
      "player7_KDAratio 0.010891\n",
      "player9_KDAratio 0.005626\n",
      "player10_KDAratio 0.005391\n",
      "Blue_LrgstKillSpree 0.115219\n",
      "Blue_TtlDmg 0.007152\n"
     ]
    }
   ],
   "source": [
    "print('---------------------\\nAre leftover features important?\\n---------------------\\n')\n",
    "\n",
    "for feature, importance in zip(not_imp_train.columns, [round(i, 6) for i in xgb_imp.feature_importances_]):\n",
    "    if importance > 0.005:\n",
    "        print(feature, importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = ['Blue_FirstTower', 'Blue_FirstInhib', 'Blue_FirstDragon', \n",
    "             'Blue_FirstHerald', 'Blue_KillsTower', 'Blue_KillsInhib', \n",
    "             'Blue_KillsBaron', 'Purp_FirstInhib', 'Purp_FirstHerald', \n",
    "             'Purp_KillsTower', 'Purp_KillsInhib', 'Purp_KillsBaron', \n",
    "             'Blue_KDAratio', 'Blue_TtlGold', 'Purp_KDAratio', 'Purp_TtlGold']\n",
    "\n",
    "X_train, X_cv, X_test = X_train[important], X_cv[important], X_test[important]\n",
    "\n",
    "train_idx = X_train.index\n",
    "cv_idx = X_cv.index\n",
    "test_idx = X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;There are some features like Blue_LrgstTimeLiving or some player features that probably wound up above the 0.002 threshold because of some random (most likely statistically insignificant) outcome. That is why I handpicked the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference Team Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y1 = data['diff_team'].iloc[:, 10:], data['diff_team']['Blue_Won']\n",
    "\n",
    "X1_train, y1_train = X1.iloc[train_idx], y1[train_idx]\n",
    "X1_cv, y1_cv = X1.iloc[cv_idx], y1[cv_idx]\n",
    "X1_test, y1_test = X1.iloc[test_idx], y1[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score: 0.9517714523064579\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=50, max_depth=X1_train.shape[1], n_jobs=-1)\n",
    "\n",
    "xgb.fit(X1_train, y1_train)\n",
    "print('r2 score:', r2_score(y1_cv, xgb.predict(X1_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Important features\n",
      "---------------------\n",
      "\n",
      "KillsTower 0.015896\n",
      "KillsInhib 0.051395\n",
      "TtlGold 0.876719\n"
     ]
    }
   ],
   "source": [
    "important = get_importances(X1_train.columns, xgb, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping features, renaming and merging\n",
    "X1_train, X1_cv, X1_test = X1_train[important], X1_cv[important], X1_test[important]\n",
    "\n",
    "X1_train.columns = ['Diff_'+i for i in important]\n",
    "X1_cv.columns = ['Diff_'+i for i in important]\n",
    "X1_test.columns = ['Diff_'+i for i in important]\n",
    "\n",
    "X_train = pd.concat([X_train, X1_train], axis=1)\n",
    "X_cv = pd.concat([X_cv, X1_cv], axis=1)\n",
    "X_test = pd.concat([X_test, X1_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compact Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score, compact: 0.9452791478092504 \n",
      "\n",
      "---------------------\n",
      "Important features\n",
      "---------------------\n",
      "\n",
      "Blue_FirstInhib 0.021692\n",
      "Blue_KillsTower 0.071738\n",
      "Blue_KillsInhib 0.044275\n",
      "Purp_KillsTower 0.049151\n",
      "Purp_KillsInhib 0.06694\n",
      "Blue_KDAratio 0.455425\n",
      "Purp_KDAratio 0.195509\n",
      "\n",
      "r2 score, important compact: 0.943424203667191\n"
     ]
    }
   ],
   "source": [
    "X1, y1 = data['compact'].iloc[:, 1:], data['compact']['Blue_Won']\n",
    "X1 = X1[[i for i in X1 if 'Role' not in i]]\n",
    "\n",
    "X1_train, y1_train = X1.iloc[train_idx], y1[train_idx]\n",
    "X1_cv, y1_cv = X1.iloc[cv_idx], y1[cv_idx]\n",
    "X1_test, y1_test = X1.iloc[test_idx], y1[test_idx]\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=50, max_depth=X1_train.shape[1], n_jobs=-1)\n",
    "\n",
    "xgb.fit(X1_train, y1_train)\n",
    "print('r2 score, compact:', r2_score(y1_cv, xgb.predict(X1_cv)), '\\n')\n",
    "\n",
    "important = get_importances(X1_train.columns, xgb, threshold=0.005)\n",
    "\n",
    "xgb.fit(X1_train[important], y1_train)\n",
    "print('\\nr2 score, important compact:',r2_score(y1_cv, xgb.predict(X1_cv[important])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;It seems like I shouldn't have made the assumptions about the data to make a compact one, feature importance on the vanilla was enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score, merged: 0.9531626604130023\n"
     ]
    }
   ],
   "source": [
    "# Merged score\n",
    "xgb = XGBClassifier(n_estimators=50, max_depth=X_train.shape[1], n_jobs=-1)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print('r2 score, merged:', r2_score(y_cv, xgb.predict(X_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------\n",
      " Blue_FirstTower \n",
      "---------------------\n",
      "\n",
      "\n",
      "---------------------\n",
      " Blue_FirstInhib \n",
      "---------------------\n",
      "\n",
      "Blue_KillsTower 0.8042\n",
      "Blue_KillsInhib 0.8902\n",
      "Diff_KillsInhib 0.8313\n",
      "\n",
      "---------------------\n",
      " Blue_FirstDragon \n",
      "---------------------\n",
      "\n",
      "\n",
      "---------------------\n",
      " Blue_FirstHerald \n",
      "---------------------\n",
      "\n",
      "\n",
      "---------------------\n",
      " Blue_KillsTower \n",
      "---------------------\n",
      "\n",
      "Blue_FirstInhib 0.8042\n",
      "Blue_KillsInhib 0.8826\n",
      "Diff_KillsTower 0.8887\n",
      "Diff_KillsInhib 0.8017\n",
      "Diff_TtlGold 0.8142\n",
      "\n",
      "---------------------\n",
      " Blue_KillsInhib \n",
      "---------------------\n",
      "\n",
      "Blue_FirstInhib 0.8902\n",
      "Blue_KillsTower 0.8826\n",
      "Diff_KillsTower 0.8066\n",
      "Diff_KillsInhib 0.8654\n",
      "\n",
      "---------------------\n",
      " Blue_KillsBaron \n",
      "---------------------\n",
      "\n",
      "\n",
      "---------------------\n",
      " Purp_FirstInhib \n",
      "---------------------\n",
      "\n",
      "Purp_KillsInhib 0.8803\n",
      "Diff_KillsInhib -0.835\n",
      "\n",
      "---------------------\n",
      " Purp_FirstHerald \n",
      "---------------------\n",
      "\n",
      "\n",
      "---------------------\n",
      " Purp_KillsTower \n",
      "---------------------\n",
      "\n",
      "Purp_KillsInhib 0.8848\n",
      "Diff_KillsTower -0.8918\n",
      "Diff_KillsInhib -0.81\n",
      "Diff_TtlGold -0.8192\n",
      "\n",
      "---------------------\n",
      " Purp_KillsInhib \n",
      "---------------------\n",
      "\n",
      "Purp_FirstInhib 0.8803\n",
      "Purp_KillsTower 0.8848\n",
      "Diff_KillsTower -0.8075\n",
      "Diff_KillsInhib -0.8698\n",
      "\n",
      "---------------------\n",
      " Purp_KillsBaron \n",
      "---------------------\n",
      "\n",
      "\n",
      "---------------------\n",
      " Blue_KDAratio \n",
      "---------------------\n",
      "\n",
      "Purp_KDAratio -0.9366\n",
      "Diff_TtlGold 0.8913\n",
      "\n",
      "---------------------\n",
      " Blue_TtlGold \n",
      "---------------------\n",
      "\n",
      "\n",
      "---------------------\n",
      " Purp_KDAratio \n",
      "---------------------\n",
      "\n",
      "Blue_KDAratio -0.9366\n",
      "Diff_TtlGold -0.8911\n",
      "\n",
      "---------------------\n",
      " Purp_TtlGold \n",
      "---------------------\n",
      "\n",
      "\n",
      "---------------------\n",
      " Diff_KillsTower \n",
      "---------------------\n",
      "\n",
      "Blue_KillsTower 0.8887\n",
      "Blue_KillsInhib 0.8066\n",
      "Purp_KillsTower -0.8918\n",
      "Purp_KillsInhib -0.8075\n",
      "Diff_KillsInhib 0.9064\n",
      "Diff_TtlGold 0.9066\n",
      "\n",
      "---------------------\n",
      " Diff_KillsInhib \n",
      "---------------------\n",
      "\n",
      "Blue_FirstInhib 0.8313\n",
      "Blue_KillsTower 0.8017\n",
      "Blue_KillsInhib 0.8654\n",
      "Purp_FirstInhib -0.835\n",
      "Purp_KillsTower -0.81\n",
      "Purp_KillsInhib -0.8698\n",
      "Diff_KillsTower 0.9064\n",
      "\n",
      "---------------------\n",
      " Diff_TtlGold \n",
      "---------------------\n",
      "\n",
      "Blue_KillsTower 0.8142\n",
      "Purp_KillsTower -0.8192\n",
      "Blue_KDAratio 0.8913\n",
      "Purp_KDAratio -0.8911\n",
      "Diff_KillsTower 0.9066\n"
     ]
    }
   ],
   "source": [
    "# SpearmanR correlation between the forest features\n",
    "import scipy\n",
    "spearman = np.round(scipy.stats.spearmanr(X_train).correlation, 4)\n",
    "\n",
    "for idx, col in enumerate(X_train.columns):\n",
    "    curr_corr = spearman[idx].tolist()\n",
    "    print('\\n---------------------\\n', col, '\\n---------------------\\n')\n",
    "    \n",
    "    for corr in curr_corr:\n",
    "        curr_idx = curr_corr.index(corr)\n",
    "\n",
    "        if abs(corr)>0.8 and idx != curr_idx:\n",
    "            print(X_train.columns[curr_idx], corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score, merged, without Blue_FirstTower: 0.9541\n",
      "r2 score, merged, without Blue_FirstInhib: 0.9536\n",
      "r2 score, merged, without Blue_FirstDragon: 0.9546\n",
      "r2 score, merged, without Blue_FirstHerald: 0.9508\n",
      "r2 score, merged, without Blue_KillsTower: 0.955\n",
      "r2 score, merged, without Blue_KillsInhib: 0.9499\n",
      "r2 score, merged, without Blue_KillsBaron: 0.9541\n",
      "r2 score, merged, without Purp_FirstInhib: 0.9527\n",
      "r2 score, merged, without Purp_FirstHerald: 0.9546\n",
      "r2 score, merged, without Purp_KillsTower: 0.9518\n",
      "r2 score, merged, without Purp_KillsInhib: 0.9513\n",
      "r2 score, merged, without Purp_KillsBaron: 0.9541\n",
      "r2 score, merged, without Blue_KDAratio: 0.9573\n",
      "r2 score, merged, without Blue_TtlGold: 0.9513\n",
      "r2 score, merged, without Purp_KDAratio: 0.9541\n",
      "r2 score, merged, without Purp_TtlGold: 0.9546\n",
      "r2 score, merged, without Diff_KillsTower: 0.955\n",
      "r2 score, merged, without Diff_KillsInhib: 0.9527\n",
      "r2 score, merged, without Diff_TtlGold: 0.9508\n"
     ]
    }
   ],
   "source": [
    "# Do we want to drop any features to reduce the feature space\n",
    "for feature in X_train.columns:\n",
    "    xgb.fit(X_train.drop(feature, axis=1), y_train)\n",
    "    print(f'r2 score, merged, without {feature}:', \n",
    "          round(r2_score(y_cv, xgb.predict(X_cv.drop(feature, axis=1))), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Types</th>\n",
       "      <th>Counts</th>\n",
       "      <th>Distincts</th>\n",
       "      <th>Nulls</th>\n",
       "      <th>Missing ratio (%)</th>\n",
       "      <th>Uniques</th>\n",
       "      <th>Skewness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0.0, 1.0]]</td>\n",
       "      <td>-0.019185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0.0, 1.0]]</td>\n",
       "      <td>0.289593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[1.0, 0.0]]</td>\n",
       "      <td>0.045161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0.0, 1.0]]</td>\n",
       "      <td>0.157846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_KillsTower</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[4.0, 8.0, 3.0, 10.0, 7.0, 9.0, 0.0, 1.0, 11....</td>\n",
       "      <td>0.062150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_KillsInhib</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0.0, 2.0, 3.0, 1.0, 4.0]]</td>\n",
       "      <td>1.128625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_KillsBaron</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0.0, 1.0, 2.0]]</td>\n",
       "      <td>1.215781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[1.0, 0.0]]</td>\n",
       "      <td>0.276576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[1.0, 0.0]]</td>\n",
       "      <td>0.314894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purp_KillsTower</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[5.0, 2.0, 10.0, 3.0, 6.0, 11.0, 0.0, 1.0, 8....</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purp_KillsInhib</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[1.0, 0.0, 2.0, 3.0, 4.0]]</td>\n",
       "      <td>1.125281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purp_KillsBaron</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[1.0, 0.0, 2.0]]</td>\n",
       "      <td>1.037296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_KDAratio</th>\n",
       "      <td>float64</td>\n",
       "      <td>34509</td>\n",
       "      <td>3962</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[1.4444444444444444, 6.166666666666668, 0.956...</td>\n",
       "      <td>6.815680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue_TtlGold</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>25050</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[60666.0, 52028.0, 39264.0, 56568.0, 66517.0,...</td>\n",
       "      <td>-0.007774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purp_KDAratio</th>\n",
       "      <td>float64</td>\n",
       "      <td>34509</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[2.4838709677419355, 1.0769230769230769, 4.72...</td>\n",
       "      <td>3.839405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purp_TtlGold</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>25106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[70231.0, 40772.0, 47894.0, 51034.0, 62457.0,...</td>\n",
       "      <td>-0.027129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diff_KillsTower</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-1.0, 6.0, -7.0, 7.0, 1.0, -10.0, 8.0, 9.0, ...</td>\n",
       "      <td>0.025721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diff_KillsInhib</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-1.0, 2.0, -2.0, 3.0, 0.0, -3.0, 1.0, -4.0, ...</td>\n",
       "      <td>-0.003510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diff_TtlGold</th>\n",
       "      <td>int64</td>\n",
       "      <td>34509</td>\n",
       "      <td>20665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-9565.0, 11256.0, -8630.0, 5534.0, 4060.0, 8...</td>\n",
       "      <td>0.049999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Types  Counts  Distincts  Nulls  Missing ratio (%)  \\\n",
       "Blue_FirstTower     int64   34509          2      0                0.0   \n",
       "Blue_FirstInhib     int64   34509          2      0                0.0   \n",
       "Blue_FirstDragon    int64   34509          2      0                0.0   \n",
       "Blue_FirstHerald    int64   34509          2      0                0.0   \n",
       "Blue_KillsTower     int64   34509         12      0                0.0   \n",
       "Blue_KillsInhib     int64   34509          5      0                0.0   \n",
       "Blue_KillsBaron     int64   34509          3      0                0.0   \n",
       "Purp_FirstInhib     int64   34509          2      0                0.0   \n",
       "Purp_FirstHerald    int64   34509          2      0                0.0   \n",
       "Purp_KillsTower     int64   34509         12      0                0.0   \n",
       "Purp_KillsInhib     int64   34509          5      0                0.0   \n",
       "Purp_KillsBaron     int64   34509          3      0                0.0   \n",
       "Blue_KDAratio     float64   34509       3962      0                0.0   \n",
       "Blue_TtlGold        int64   34509      25050      0                0.0   \n",
       "Purp_KDAratio     float64   34509       4005      0                0.0   \n",
       "Purp_TtlGold        int64   34509      25106      0                0.0   \n",
       "Diff_KillsTower     int64   34509         23      0                0.0   \n",
       "Diff_KillsInhib     int64   34509          9      0                0.0   \n",
       "Diff_TtlGold        int64   34509      20665      0                0.0   \n",
       "\n",
       "                                                            Uniques  Skewness  \n",
       "Blue_FirstTower                                        [[0.0, 1.0]] -0.019185  \n",
       "Blue_FirstInhib                                        [[0.0, 1.0]]  0.289593  \n",
       "Blue_FirstDragon                                       [[1.0, 0.0]]  0.045161  \n",
       "Blue_FirstHerald                                       [[0.0, 1.0]]  0.157846  \n",
       "Blue_KillsTower   [[4.0, 8.0, 3.0, 10.0, 7.0, 9.0, 0.0, 1.0, 11....  0.062150  \n",
       "Blue_KillsInhib                         [[0.0, 2.0, 3.0, 1.0, 4.0]]  1.128625  \n",
       "Blue_KillsBaron                                   [[0.0, 1.0, 2.0]]  1.215781  \n",
       "Purp_FirstInhib                                        [[1.0, 0.0]]  0.276576  \n",
       "Purp_FirstHerald                                       [[1.0, 0.0]]  0.314894  \n",
       "Purp_KillsTower   [[5.0, 2.0, 10.0, 3.0, 6.0, 11.0, 0.0, 1.0, 8....  0.024500  \n",
       "Purp_KillsInhib                         [[1.0, 0.0, 2.0, 3.0, 4.0]]  1.125281  \n",
       "Purp_KillsBaron                                   [[1.0, 0.0, 2.0]]  1.037296  \n",
       "Blue_KDAratio     [[1.4444444444444444, 6.166666666666668, 0.956...  6.815680  \n",
       "Blue_TtlGold      [[60666.0, 52028.0, 39264.0, 56568.0, 66517.0,... -0.007774  \n",
       "Purp_KDAratio     [[2.4838709677419355, 1.0769230769230769, 4.72...  3.839405  \n",
       "Purp_TtlGold      [[70231.0, 40772.0, 47894.0, 51034.0, 62457.0,... -0.027129  \n",
       "Diff_KillsTower   [[-1.0, 6.0, -7.0, 7.0, 1.0, -10.0, 8.0, 9.0, ...  0.025721  \n",
       "Diff_KillsInhib   [[-1.0, 2.0, -2.0, 3.0, 0.0, -3.0, 1.0, -4.0, ... -0.003510  \n",
       "Diff_TtlGold      [[-9565.0, 11256.0, -8630.0, 5534.0, 4060.0, 8...  0.049999  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eds.look(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAEXCAYAAACtXBnmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5xdZX3o/883mUwmIZBwCTGEIAkCNlVEjYhttagg8fwUPKdYgxSw5QenVlpL5RRSL7WUFlAs0oqXUCneg2LVqNhwEaztASQoys1oCLeQAJGEhNxIZuZ7/lhrZ3aGmczemT2zJ7M/79drv/baz3rWc5k9e5757udZa0VmIkmSJEnSSDWm2Q2QJEmSJGlXDFwlSZIkSSOagaskSZIkaUQzcJUkSZIkjWgGrpIkSZKkEc3AVZIkSZI0ohm4Sk0UEfdHxHHNbockSWqeiLg2Ii5udjukkczAVRpCEfFIRBzfK+09EfFfAJn525l52wBlHBoRGRFtQ9hUSZLEjrF7S0RsjIh1EfH9iJjZ7HZVlP8TvKTZ7ZCGm4Gr1OIMiCVJeoG3Z+YkYDrwFPAvTW6P1PIMXKUmqp6RjYhjImJpRGyIiKci4p/KbP9ZPj9bfvv7uogYExEfiohHI+LpiPhiREyuKveMct8zEfHhXvV8NCKuj4gvR8QG4D1l3bdHxLMRsToiPhUR7VXlZUT8WUT8OiKei4i/j4jDymM2RMTXq/NLkjQaZOZW4HpgDkBETC7H3DXlOPuhiBhT7vtMRFxfOTYiLouIW6JwXESsjIi/iYjflOPyaf3VGxFnR8TyiFgbEYsj4qAyvfI/wc/L/wneNWSdl0YYA1dp5LgSuDIz9wEOA75epr+hfJ6SmZMy83bgPeXjjcBsYBLwKYCImAN8GjiN4pviycCMXnWdTDEQTwG+AnQB5wEHAK8D3gz8Wa9j5gGvBo4F/hpYWNYxE3gZcOog+i5J0ogTEROBdwF3lEn/QjGuzgZ+HzgD+ONy3weAo8pTgl4PnAWcmZlZ7n8RxTg7AzgTWBgRR/ZR55uAS4A/pBjHHwUWAWRm5X+CV5T/E1zXwO5KI5qBqzT0vl3OZD4bEc9SBJV92Q68JCIOyMyNmXlHP/mgCBj/KTNXZOZGYAEwv1z2ewrw3cz8r8zcBnwEyF7H356Z387M7szckpl3Z+YdmdmZmY8An6MYkKtdlpkbMvN+4D7gxrL+9cAPgFfW/iORJGlE+3Y5Zm8ATgA+HhFjKYLYBZn5XDlefgI4HSAzNwN/BPwT8GXgzzNzZa9yP5yZz2fmj4DvUwSnvZ0GXJOZP83M5ynG+NdFxKEN7qO0RzFwlYbeOzJzSuXBC2cyK84CjgB+GRF3RcTbdlHmQRTfwFY8CrQB08p9j1d2lAPpM72Of7z6RUQcERHfi4gny+XD/0jxrXC1p6q2t/TxetIu2itJ0p7kHeWYPR44F/gRcDDQzgvH3x2rmjLzJ8AKIOhZOVWxLjM39Tr2oD7q3mmML7+gfoYXrp6SWoqBqzRCZOavM/NU4EDgMuD6iNiLF86WAqwCXlz1+hCgkyKYXE0xuAIQEROA/XtX1+v1Z4BfAoeXS5X/hmLQlSSpZWVmV2b+O8UpNcdSrI7qPf4+UXkREe+jCHZXUZxWU23fclyvPnZVH9XuNMaXx+xfXY/UigxcpREiIv4oIqZmZjfwbJncBawBuinOp6n4GnBeRMyKiEkUM6TXZWYnxbmrb4+I3ykvmPR3DByE7k2xHGpjRLwUeG/DOiZJ0h6qvLDSycC+FKfJfB34h4jYOyJeDPwVxbJgIuII4GKK5cKnA38dEUf3KvLvIqK9PAf2bcA3+qj2q8AfR8TRETGeYoy/s1yaDMWX1LP7OE4a1QxcpZFjHnB/RGykuFDT/MzcWi71/Qfgv8vzZI8FrgG+RHHF4YeBrcCfA5TnoP45xYUcVgPPAU8Dz++i7vOBd5d5rwa82IMkqZV9txyPN1CMwWdWja+bKJYD/xdFkHlNeY2JL1NcD+LnmflritVLXyqDT4AngXUUM6pfAf40M3/Zu+LMvAX4MPBNinH8MGB+VZaPAl8o/yfo6xxZaVSKngudSRqNyhnZZymWAT/c7PZIktRqIuI44MuZefBAeSX1zRlXaRSKiLdHxMTyvJjLgXuBR5rbKkmSJGn3GLhKo9PJFEuRVgGHUyw7dnmFJEmS9kguFZYkSZIkjWjOuEqSJEmSRrS2ZjegHgcccEAeeuihzW6GJGmUuPvuu3+TmVOb3Y49mWOzJKmR+hub96jA9dBDD2Xp0qXNboYkaZSIiEeb3YY9nWOzJKmR+hubXSosSZIkSRrRDFwlSZIkSSOagaskSZIkaUQzcJUkSZIkjWgGrpIkSZKkEc3AVZIkSZI0ohm4SpIkSZJGNANXSZIkSdKIZuDah1tvhR//uNmtkCRJkiQBtDW7Ac20cGHf6ZdcAu3tsGzZ8LZHkiRJkvRCLR249mfjRujoaHYrJEmSJElQ41LhiJgXEcsiYnlEXNjH/r+KiAci4hcRcUtEvLhq35kR8evycWZV+qsj4t6yzH+OiGhMlwZv82bYsqXZrZAkSZIkQQ2Ba0SMBa4C3grMAU6NiDm9sv0MmJuZRwHXAx8rj90P+FvgtcAxwN9GxL7lMZ8BzgEOLx/zBt2bBujqMnCVJEmSpJGklhnXY4DlmbkiM7cBi4CTqzNk5q2Zubl8eQdwcLl9InBTZq7NzHXATcC8iJgO7JOZt2dmAl8E3tGA/gxaJWDduhUym9sWSZIkSVJtgesM4PGq1yvLtP6cBfxggGNnlNsDlhkR50TE0ohYumbNmhqaOzibNhXP3d0925IkSZKk5qklcO3r3NM+5yIj4o+AucDHBzi25jIzc2Fmzs3MuVOnTq2huYOzcWPP9oYNQ16dJEmSJGkAtQSuK4GZVa8PBlb1zhQRxwMfBE7KzOcHOHYlPcuJ+y2zGTZv7tlev7557ZAkSZIkFWoJXO8CDo+IWRHRDswHFldniIhXAp+jCFqfrtq1BHhLROxbXpTpLcCSzFwNPBcRx5ZXEz4D+E4D+jNo1TOuBq6SJEmS1HwD3sc1Mzsj4lyKIHQscE1m3h8RFwFLM3MxxdLgScA3yrvaPJaZJ2Xm2oj4e4rgF+CizFxbbr8XuBaYQHFO7A8YAarPazVwlSRJkqTmGzBwBcjMG4AbeqV9pGr7+F0cew1wTR/pS4GX1dzSYeJSYUmSmuvqq69mxYoVAKxevRqA6dOn75Rn9uzZnH322cPeNklSc9QUuLYSlwpLktRcK1as4Oc/f4itW2fQ0VEshXrssa079nd0PNGspkmSmsTAtZfNm2GffYorChu4SpLUHFu3zuDhh9/PrFlXAvDww+/fsa+SJklqHbVcnKmlbNwI++0HEd4OR5IkSZJGAgPXXjZtgkmToKPDGVdJkiRJGgkMXHvZvBn22gsmTDBwlSRJkqSRwMC1l40bDVwlSZIkaSQxcK3S1QVbtxaBq0uFJUmSJGlkMHCtsqm44r4zrpIkSZI0ghi4Vtm8uXg2cJUkSZKkkcPAtUrvGVdvhyNJkiRJzWfgWmXjxuLZGVdJkiRJGjkMXKv0Xiq8bVtxsSZJkiRJUvMYuFbpPeMKzrpKkiRJUrMZuFbZtAnGjCmC1o6OIs3AVZIkSZKay8C1yubNMHEiRDjjKkmSJEkjhYFrlY0bi2XCYOAqSZIkSSNFTYFrRMyLiGURsTwiLuxj/xsi4qcR0RkRp1SlvzEi7ql6bI2Id5T7ro2Ih6v2Hd24bu2ezZtfGLh6SxxJkiRJaq62gTJExFjgKuAEYCVwV0QszswHqrI9BrwHOL/62My8FTi6LGc/YDlwY1WW/5OZ1w+mA420cSNMmVJsO+MqSZIkSSNDLTOuxwDLM3NFZm4DFgEnV2fIzEcy8xdA9y7KOQX4QWZu3u3WDrG+ZlwNXCVJkiSpuWoJXGcAj1e9Xlmm1Ws+8LVeaf8QEb+IiCsiYnxfB0XEORGxNCKWrlmzZjeqrd2mTQaukiRJkjTS1BK4Rh9pWU8lETEdeDmwpCp5AfBS4DXAfsAFfR2bmQszc25mzp06dWo91dalsxO2bu0JXMeMKbYNXCVJkiSpuWoJXFcCM6teHwysqrOePwS+lZnbKwmZuToLzwP/RrEkuWk2lwuYK4ErwOTJBq6SJEmS1Gy1BK53AYdHxKyIaKdY8ru4znpOpdcy4XIWlogI4B3AfXWW2VAbNxbPBq6SJEmSNLIMGLhmZidwLsUy3weBr2fm/RFxUUScBBARr4mIlcA7gc9FxP2V4yPiUIoZ2x/1KvorEXEvcC9wAHDx4Luz+/qbcfV2OJIkSZLUXAPeDgcgM28AbuiV9pGq7bsolhD3dewj9HExp8x8Uz0NHWqbNhXPvQPXdeua0x5JkiRJUqGWpcItwaXCkiRJkjQyGbiWvDiTJEmSJI1MBq6ljRuLW+B0dPSk7bOPgaskSZIkNZuBa2nz5mK2NaruWjt5MmzZAtu393+cJEmSJGloGbiWNm2CiRN3Tps8uXh21lWSJEmSmsfAtdTZCePG7ZxWCVy9JY4kSZIkNY+Ba6m7uzjHtZozrpIkSZLUfAaupa4uGDt25zQDV0mSJElqPgPXkoGrJEmSJI1MBq6lrq4XLhXeZ5/i2cBVkiRJkprHwLXU3e2MqyRJkiSNRAauJZcKS5IkSdLIZOBa6uuqwu3t0NHh7XAkSZIkqZkMXEt9zbhCMevqjKskSZIkNY+Ba6mvizMB7LsvrF07/O2RJEmSJBUMXEv9zbgeeCA89dTwt0eSJEmSVKgpcI2IeRGxLCKWR8SFfex/Q0T8NCI6I+KUXvu6IuKe8rG4Kn1WRNwZEb+OiOsion3w3dl9fV1VGGDaNHj66eFvjyRJkiSpMGDgGhFjgauAtwJzgFMjYk6vbI8B7wG+2kcRWzLz6PJxUlX6ZcAVmXk4sA44azfa3zD9zbhOm+aMqyRJkiQ1Uy0zrscAyzNzRWZuAxYBJ1dnyMxHMvMXQHctlUZEAG8Cri+TvgC8o+ZWD4G+rioMReD67LPw/PPD3yZJklrB1VdfzdVXX73Hli9JGnptNeSZATxe9Xol8No66uiIiKVAJ3BpZn4b2B94NjM7q8qcUUeZDberGVcolgvPnDm8bZIkqRWsWLFijy5fkjT0aglco4+0rKOOQzJzVUTMBn4YEfcCfd0Ztc8yI+Ic4ByAQw45pI5q69PfVYUrgetTTxm4SpIkSVIz1LJUeCVQHbIdDKyqtYLMXFU+rwBuA14J/AaYEhGVwLnfMjNzYWbOzcy5U6dOrbXauu3q4kzgea6SJEmS1Cy1BK53AYeXVwFuB+YDiwc4BoCI2DcixpfbBwC/CzyQmQncClSuQHwm8J16G99IAy0VNnCVJEmSpOYYMHAtz0M9F1gCPAh8PTPvj4iLIuIkgIh4TUSsBN4JfC4i7i8P/y1gaUT8nCJQvTQzHyj3XQD8VUQspzjn9fON7Fg9Mp1xlSRJkqSRqpZzXMnMG4AbeqV9pGr7Lorlvr2P+7/Ay/spcwXFFYubrru8FnJf57hOmAB7723gKkmSJEnNUstS4VGvq6t47mvGFbyXqyRJkiQ1k4ErBq6SJEmSNJIZuNKzVNjAVZIkSZJGHgNXemZc+zrHFQxcJUmSJKmZDFypbanwM8/A9u3D1yZJkiRJUsHAldpmXAHWrBme9kiSJEmSehi4Uts5ruByYUmSJElqBgNXalsqDAaukiRJktQMBq70zLgOtFTYwFWSJEmShp+BK864SpIkSdJI1tbsBowE/QWuCxf2bLe3w003wZQpxetzzhmetkmSJElSq3PGlYFnXAH22Qc2bBie9kiSJEmSehi4MvA5rgB77w3PPTc87ZEkSZIk9TBwxRlXSZIkSRrJDFzpCVwHmnE1cJUkSZKk4WfgSu0zrhs39iwrliRJkiQNDwNXeoLRgQLXzCJ4lSRJkiQNn5oC14iYFxHLImJ5RFzYx/43RMRPI6IzIk6pSj86Im6PiPsj4hcR8a6qfddGxMMRcU/5OLoxXapfrYEruFxYkiRJkobbgPdxjYixwFXACcBK4K6IWJyZD1Rlewx4D3B+r8M3A2dk5q8j4iDg7ohYkpnPlvv/T2ZeP9hODFat57iCgaskSZIkDbcBA1fgGGB5Zq4AiIhFwMnAjsA1Mx8p9+10Bmhm/qpqe1VEPA1MBZ5lBKn1HFcwcJUkSZKk4VbLUuEZwONVr1eWaXWJiGOAduChquR/KJcQXxER4/s57pyIWBoRS9esWVNvtTWpJ3D1Xq6SJEmSNLxqCVyjj7Ssp5KImA58CfjjzKzMyi4AXgq8BtgPuKCvYzNzYWbOzcy5U6dOrafamtVyjuuECdDW5oyrJEmSJA23WgLXlcDMqtcHA6tqrSAi9gG+D3woM++opGfm6iw8D/wbxZLkpqjlHNeIInjdunV42iRJkiRJKtQSuN4FHB4RsyKiHZgPLK6l8DL/t4AvZuY3eu2bXj4H8A7gvnoa3ki1LBWGInDdsmXo2yNJkiRJ6jFg4JqZncC5wBLgQeDrmXl/RFwUEScBRMRrImIl8E7gcxFxf3n4HwJvAN7Tx21vvhIR9wL3AgcAFze0Z3WoZcYVoKPDGVdJkiRJGm61XFWYzLwBuKFX2keqtu+iWELc+7gvA1/up8w31dXSIVTLOa7gjKskSZIkNUMtS4VHvVqXCjvjKkmSJEnDz8CVnhnX6Ov6yVWccZUkSZKk4WfgSjHjOnbswIGrM66SJEmSNPwMXCkC14EuzARF4LplC2Rdd7GVJEmSJA2GgSs9M64DmTChWFa8ffvQt0mSJEmSVDBwpQhGawlcOzqKZ5cLS5IkSdLwMXClvhlX8AJNkiRJkjScarqP62jX3V37Oa7gjKskSXuS++67D4C3v/3tw1LfXnvtxaZNm3aZZ/Lkyaxfv55p06Zxxhln8IlPfIKLLrqI9evX8/GPfxyAAw44gA0bNrBt2zYuvvhiZs6cyT/+4z+yfft2urq6eOqpp5g2bRoATz31FDNmzOAv/uIv+PSnP01mcvrpp3PJJZdw6aWXkpksWLCABQsWcO2117Jq1Souu+wynn32WT760Y/uVPf73vc+/uM//mNHnlmzZu1o99q1a/nYxz7GBRdcwL777vuCfq1YsYIFCxZw6aWXMnny5B15M3PH9rp163bkqS67P/3VWW96LWUONq/UiobrM+KMK/XPuBq4SpKk/gwUtAKsX78eKALOK664gu7ubi699FKuuOKKHXl+85vfsG3bNgAuvfRSFi1axLJly1ixYgWPPvooW7du5dFHH92x/dBDD/GJT3yCZcuW8atf/YrLLruMzZs3c/nll3P55ZezefNmLrvsMh566CG2bNnC5ZdfzmWXXfaCuj/96U/vlKfaokWLeOCBB1i0aFGf/arUc/nll++Ut3q7Ok8t+quz3vR68+xOXqkVDddnxMCV2gPXyoyrS4UlSdozDNcs62B0dnYCsHHjxh3bvW3cuJElS5YMWNZjjz220zGVtMcff3yntEp6Jciurjurbp/w2GOP8fDDDwPFrMott9xCZnLzzTezbt26nepesWLFjnoee+wxbrrpJjKTm266iZtvvpnM5MYbb9wpT6Xs/vRXZ73ptZRZT/2SCsP5GXGpMJ7jKklSM61evZotW7awYMECoAiA2tvH9Zu/vX0NK1Zs35G/VXR3dzel3ssvv5yrrrqKRYsW7WhDd3c3ixYt4r3vfe9O+apVAuHqYLx3YF4puz/91Vlvei1l1lO/pMJwfkacccVzXCVJqkdEnBMRSyNi6Zo1a5rdHA2xyizubbfdtlMweuutt+6UrzKT2ltm7jSL21fZ/emvznrTaymznvolFYbzM+KMKy4VliSpHpm5EFgIMHfu3L4jkjpMnz4dgEsuuQSABQsWcOed/X9LvG3bVGbP7tiRf1f2hKXCI90hhxwCwHHHHcdNN91EZ2cnbW1tvPGNb9wp38yZM/sMXiMCoM/gtVJ2f/qrs970Wsqsp35JheH8jDjjShG41jLjOm4ctLU54ypJkobfmFr+WRkC559/PgDz58/f0YYxY8Ywf/78PvNVtLW17Xiu3t7VMb31V2e96bWUWU/9kgrD+RkxcKVYKlzLjCsU57kauEqStGf47ne/2+wmDKgSzE2aNOkFgV3FpEmTOPHEEwcsq3oGc9KkSTvSZs6cuVNaJX2vvfZ6Qd2VGdJKnsota/bbbz/e/OY3ExEcf/zxL7jtxezZs3fUc8ghh3DCCScQEZxwwgkcf/zxRARvectbdsoz0O1w+quz3vRayqynfkmF4fyMGLhS+1JhKJYLu1RYkiT1pxIM7srkyZMBmDZtGueddx5jxozhwgsv5LzzztuR54ADDqC9vR2ACy+8kPnz53PkkUcye/ZsXvziF9PR0cGLX/ziHduHHXYYH/jABzjyyCM54ogjuOCCC5g4cSLnn38+559/PhMnTuSCCy7gsMMOY8KECZx//vlccMEFL6j7z/7sz3bKU23+/PnMmTOn31mVSj3nn3/+Tnmrt6vz1KK/OutNrzfP7uSVWtFwfUaiv5Pld8oUMQ+4EhgL/GtmXtpr/xuATwJHAfMz8/qqfWcCHypfXpyZXyjTXw1cC0wAbgDenwM0Zu7cubl06dLaelaDhQuL5499DNrb4S//cuBjLr4Y9t0Xfv7zhjVDktQkEXF3Zs5tdjv2ZI0YmytXB+59juvDD7+fWbOuBODhh9+/I/+sWVfy2tfWdo5rX+VLkkau/sbmAWdcI2IscBXwVmAOcGpEzOmV7THgPcBXex27H/C3wGuBY4C/jYjK/PFngHOAw8vHvDr601C1nuMKxVJhZ1wlSZIkafjUEq4dAyzPzBWZuQ1YBJxcnSEzH8nMXwC9bzB2InBTZq7NzHXATcC8iJgO7JOZt5ezrF8E3jHYzuyuegLXjg7PcZUkSZKk4VRLuDYDqL62+coyrRb9HTuj3B6wzOG4V5znuEqSJEnSyFVL4Bp9pNV6z7b+jq25zMxcmJlzM3Pu1KlTa6y2Pl5VWJIkSZJGrloC15XAzKrXBwOraiy/v2NXltu7U2bD1TvjauAqSZIkScOnlsD1LuDwiJgVEe3AfGBxjeUvAd4SEfuWF2V6C7AkM1cDz0XEsVHcLOwM4Du70f6G6O6u7+JMnZ3w/PND2yZJkiRJUmHAcC0zO4FzKYLQB4GvZ+b9EXFRRJwEEBGviYiVwDuBz0XE/eWxa4G/pwh+7wIuKtMA3gv8K7AceAj4QUN7Vod6Z1wBNmwYuvZIkiRJknq01ZIpM2+guNdqddpHqrbvYuelv9X5rgGu6SN9KfCyeho7VOoJXCdMKJ43bIAhOuVWkiRJklSlxgWyo1u9t8MBWL9+6NojSZIkSeph4Er9VxUGlwpLkiRJ0nAxcMVzXCVJkiRpJDNwZfeWChu4SpIkSdLwaPnANdOlwpIkSZI0krV84NrdXTwbuEqSJEnSyGTgWmfg2tZW5DVwlSRJkqTh0fKBa1dX8VzrOa4RxXmuBq6SJEmSNDwMXMvAtdYZVyiWC3sfV0mSJEkaHgaudc64gjOukiRJkjScWj5wrfccVzBwlSRJkqTh1PKB6+4uFTZwlSRJkqTh0fKBqzOukiRJkjSytXzgujvnuDrjKkmSJEnDx8B1N5YKO+MqSZIkScPHwHU3z3HduhW2bRuaNkmSJEmSetQUuEbEvIhYFhHLI+LCPvaPj4jryv13RsShZfppEXFP1aM7Io4u991WllnZd2AjO1aryjmu9d4OB5x1lSRJkqThMGC4FhFjgauAtwJzgFMjYk6vbGcB6zLzJcAVwGUAmfmVzDw6M48GTgceycx7qo47rbI/M59uQH/qtrszrmDgKkmSJEnDoZZ5xmOA5Zm5IjO3AYuAk3vlORn4Qrl9PfDmiIheeU4FvjaYxg6F3bk4kzOukiRJkjR8agnXZgCPV71eWab1mSczO4H1wP698ryLFwau/1YuE/5wH4EuABFxTkQsjYila9asqaG59dndizOBgaskSZIkDYdaAte+AsqsJ09EvBbYnJn3Ve0/LTNfDry+fJzeV+WZuTAz52bm3KlTp9bQ3Prszn1cXSosSZIkScOnlsB1JTCz6vXBwKr+8kREGzAZWFu1fz69Zlsz84ny+TngqxRLkoed57hKkiRJ0shWS+B6F3B4RMyKiHaKIHRxrzyLgTPL7VOAH2ZmAkTEGOCdFOfGUqa1RcQB5fY44G3AfTSBVxWWJEmSpJGtbaAMmdkZEecCS4CxwDWZeX9EXAQszczFwOeBL0XEcoqZ1vlVRbwBWJmZK6rSxgNLyqB1LHAzcHVDelSnwcy4rl2763ySJEmSpMEbMHAFyMwbgBt6pX2kansrxaxqX8feBhzbK20T8Oo62zokdidwbW+HffaBp54amjZJkiRJknrUsUB2dNqdwBVg2jQDV0mSJEkaDi0fuO7OOa4AL3oRPPlk49sjSZIkSdpZyweuzrhKkiRJ0shm4FoGrs64SpIkSdLI1PKBa2Wp8O7MuD77LDz/fOPbJEmSJEnqUdNVhUez3V0q/KIXFc9PPQWHHNLYNkmS1Epmz569R5cvSRp6LR+4DmbGFQxcJUkarLPPPnuPLl+SNPRafqnwYM5xBc9zlSRJkqShZuC6m4Fr9YyrJEmSJGnoGLh2FUFrRH3HVQJXZ1wlSZIkaWi1fODa3V3/+a0A48fDlCnOuEqSJEnSUGv5wLWra/cCV/BerpIkSZI0HAxcu+o/v7Vi2jRnXCVJkiRpqLV84Lq7S4XBGVdJkiRJGg4tH7gOZqmwM66SJEmSNPQMXAd5juuGDbBlS2PbJEmSJEnqUVPgGhHzImJZRCyPiAv72D8+Iq4r998ZEYeW6YdGxJaIuKd8fLbqmFdHxL3lMf8cUe8NaRqju3tw57iCs66SJEmSNJQGDNkiYixwFfBWYA5wakTM6ZXtLGBdZr4EuAK4rGrfQ5l5dPn406r0zwDnAIeXj3m7343dN9gZV/A8V0mSJEkaSrXMNR4DLM/MFZm5DVgEnNwrz8nAF8rt64E372oGNSKmA/tk5u2ZmcAXgXfU3foGGOxVhcEZV0mSJEkaSrWEbCWjWmQAABbGSURBVDOAx6teryzT+syTmZ3AemD/ct+siPhZRPwoIl5flX/lAGUCEBHnRMTSiFi6Zs2aGppbH2dcJUmSJGlkqyVw7WvmNGvMsxo4JDNfCfwV8NWI2KfGMovEzIWZOTcz506dOrWG5tZnMLfDOfDA4tkZV0mSJEkaOrUEriuBmVWvDwZW9ZcnItqAycDazHw+M58ByMy7gYeAI8r8Bw9Q5rAYzIzruHGw//7OuEqSJEnSUKolcL0LODwiZkVEOzAfWNwrz2LgzHL7FOCHmZkRMbW8uBMRMZviIkwrMnM18FxEHFueC3sG8J0G9Kdug7mqMHgvV0mSJEkaam0DZcjMzog4F1gCjAWuycz7I+IiYGlmLgY+D3wpIpYDaymCW4A3ABdFRCfQBfxpZq4t970XuBaYAPygfAy7rq5i5nR3vehFzrhKkiRJ0lAaMHAFyMwbgBt6pX2kansr8M4+jvsm8M1+ylwKvKyexg6Fri4YP373j582DX7yk8a1R5IkSZK0s0Eskh0dBnNxJnDGVZIkSZKGWssHroO5OBMUM66bNsHGjY1rkyRJkiSpR01LhUez3Z1xXbiweH7wweL5yiuhcreec85pTNskSZIkSc640tU1uKsK77NP8bxhQ2PaI0mSJEnamYHrIJcKVwLX9esb0x5JkiRJ0s4MXAcZuO6/f/G8Zk1j2iNJkiRJ2lnLB67d3YNbKrzXXjB5Mqxe3bg2SZIkSZJ6tHzgOtgZV4CDDoJVqxrTHkmSJEnSzgxcB3lxJoDp04sZ1+7uxrRJkiRJktTDwLVBM67btsHatY1pkyRJkiSpR8sHrrt7H9dqBx1UPLtcWJIkSZIar6UD18zGzLhOn148e4EmSZIkSWq8lg9cYfDnuE6cCFOmOOMqSZIkSUOhpQPXrq7iebAzrlDMuhq4SpIkSVLjGbgy+BlXKM5zffJJrywsSZIkSY1m4ErjZly3bYNnnhl8WZIkSZKkHjUFrhExLyKWRcTyiLiwj/3jI+K6cv+dEXFomX5CRNwdEfeWz2+qOua2ssx7yseBjepUrSqzo40IXCtXFvYCTZIkSZLUWG0DZYiIscBVwAnASuCuiFicmQ9UZTsLWJeZL4mI+cBlwLuA3wBvz8xVEfEyYAkwo+q40zJzaYP6UrdGBq6VKwt7nqskSZIkNVYtM67HAMszc0VmbgMWASf3ynMy8IVy+3rgzRERmfmzzKyEcvcDHRExvhENb4RGnuNaubKwM66SJEmS1Fi1hGwzgMerXq9k51nTnfJkZiewHti/V54/AH6Wmc9Xpf1buUz4wxERdbW8ARp5jit4ZWFJkiRJGgq1BK59BZRZT56I+G2K5cP/u2r/aZn5cuD15eP0PiuPOCcilkbE0jVr1tTQ3No1OnA96KBixtUrC0uSJElS49QSuK4EZla9PhjoPa+4I09EtAGTgbXl64OBbwFnZOZDlQMy84ny+TngqxRLkl8gMxdm5tzMnDt16tRa+lSzRp7jCkXgun07PPJIY8qTJEmSJNVwcSbgLuDwiJgFPAHMB97dK89i4EzgduAU4IeZmRExBfg+sCAz/7uSuQxup2TmbyJiHPA24OZB96ZOjTzHFeDgg4vnO+6A2bMbU6YkSa2oo+MJZs26ko6OlQDMmnXlTvvgsCa1TJLUDAMGrpnZGRHnUlwReCxwTWbeHxEXAUszczHweeBLEbGcYqZ1fnn4ucBLgA9HxIfLtLcAm4AlZdA6liJovbqB/apJowPXQw6BvfeG734X3t07tJckSTWZXfXt7+rVewEwfXpHVY7DdsojSRr9aplxJTNvAG7olfaRqu2twDv7OO5i4OJ+in117c0cGo0+x3XMGDjqKPjBD2DbNmhvb0y5kiS1krPPPrvZTZAkjTANmmvcMzX6HFeAV7wC1q+HH/+4cWVKkiRJUitr6cC10TOuAL/1W9DRAYsXN65MSZIkSWplLR24VmZcG3WOKxTLg48/vghcs/dNgyRJkiRJdWvpwHUoZlwBTjqpuCXOffc1tlxJkiRJakUGrjQ+cH3b24pnlwtLkiRJ0uAZuNL4wHX6dDjmGANXSZIkSWqElg5ch+Ic14qTToKf/AQef7zxZUuSJElSK2m5wPXee+Gqq4rtoZpxBXj3u4tyr7yy8WVLkiRJUitpucD1+9+Hc8+Fp5/uCVyHYsZ11iyYPx8++1l45pnGly9JkiRJraLlAtc3vrF4/tGPhnbGFeDCC2HTJvjUp4amfEmSJElqBW3NbsBwe9WrYNIkuPXWnnNcGx24LlzYs/2KV8DHPgb77gsdHUXaOec0tj5JkiRJGs1absZ13Dj4vd+D224b+hlXgHnzYPNm+PGPh64OSZIkSRrNWi5whWK58IMPwrPPFq+H4hzXitmz4cgj4aabYP36oatHkiRJkkarlgxcjzuueH7wweJ5KGdcAf7n/4StW+HSS2HVqqGtS5IkSZJGm5YMXF/1Kth77557rA514DprFpx/PnR2wsc/Dj/84dDWJ0mjyfLl8MlP9lyXQJIktZ6WDFzb2uD1r+95PZRLhSsOOQQuuAAmT4Y3vxle/eriH7Ennxz6uiVpT9XVVdxa7Lzz4Jprmt0aSZLULC0ZuELPbXHGjIGI4anzgAOK4PWTnyzqPe88mDkT/uAP4MYbnU2Q1Nq2boVvfxu2betJ++xn4e674aCDir+fv/lN89onSZKap6bANSLmRcSyiFgeERf2sX98RFxX7r8zIg6t2regTF8WESfWWuZQq5znOhyzrdUmTCgeZ58Nf/d3RQB9441w4omw117FTOy73uVsrKTRa+tW+OY34ZFHetKeeQaOP764JsBb31pczO7JJ+Fv/qZIX7IENmwogldJktR6BryPa0SMBa4CTgBWAndFxOLMfKAq21nAusx8SUTMBy4D3hURc4D5wG8DBwE3R8QR5TEDlTmkXvnK4r6qmcNV4wu96EVwyilw8slwzz3FeVwdHbB0KXz96/CBD8AJJ8CUKbBsWbF/8mR4yUuKx7RpsN9+xf62tp7Z48pze3uRZ/r04j6y27YV/zCOHVukt7cX7Vi3rig7oih3ypQiPbO4lU97e3EboYquruIfyEmTdk7PhO3bi7TqWezu7uL83kp91WVnFgH7cM16SyNdd/cLv1DLLD6/7e07f1a2bSse1Z+hzJ4rpk+Z0pO+dWsRCHZ0wIEHFnVkwpo1sHJlsSJkxozi78PWrfDrX8MTTxTn6M+eXfyNWbWqmP1cs6a4R/XLX16Uf8cdcPPNxef/TW8qbjm2Zg18+ctw3XVF2aefDv/rf8F3vgMf+hA89ljRn3PPhXe/G047rQhk3/9+uOqqooxZs4q2XHUVHHFEsUrl4x+HP/kT+N3fHfK3QpIkjSCRA0RuEfE64KOZeWL5egFAZl5SlWdJmef2iGgDngSmAhdW563kKw/bZZl9mTt3bi5durTOLvbvqKPgoYfgiisaVmTDrF4Nd95ZBLGZRaB54IGwZQs8/XTxT+GmTYNbXrz//kXZa9e+MH3cuCK9smRv772Lf4I3by7SK782++xTpG/aVPyz3NVV/DM6eXIxs7xhQzFzkln8wzxlSvGP8TPPFP+QAowf31Pn888XdY4ZU5QzfnxRZuUf9La2nkB6yxbYuLF4njixCKQ7OooytmwpguWOjuLR3l78rDKL5+rtyjPsHPz3td37mN7lQNHGSvC+ZUvRz+7uoh0TJhRlVfpT+YJh3Liin5X8bW09be/uLvJ2dhY/u/b2Yn9nZxEodHX11Dl2bJG2fXtx3LhxPW2ppENPeuXLhu3bi3ZV0ru6irRKnePG9dS5bVtPne3tPXVu29ZTZyXAqqRX6mxv7wnCtm/fuf+VfvZ+nzs7i/e0s7OnjEqdzz/f8zs3fnzRh+efL36GmUVaR0dR/9atxWPMmCJ9/Piizq1bi2MqP/P29qLsLVt6gsVK+tatRfr27T3vZ1tb8bnYvLloy8SJRSAJxedi48ain5MmFemdnfDcc0X6uHHFZ2vSpKLcDRuK5/Hji8/WhAlFvmefLdra3l58hsaPL75w2rix52e7335F39asKeqo/C5OnVr0r/pz3tZW/D1Zt66orzr9gAPgqad2/lKvra34TD/zzM5/Kyq/L5s3F3VX3pfKzzCzCECffLL4cmzMmKIfr3oVfPCD8L3vwbXXFvn23RcWLy7y33JLEeRu2AAf/jBcdFFR38aNMGdO8TO4++6dvzjbXRFxd2bOHXxJravRY7MkqbX1NzbXErieAszLzP+/fH068NrMPLcqz31lnpXl64eA11IEqXdk5pfL9M8DPygP22WZVWWfA5xTvjwSWFZrp2twANAqZ0y1Sl/t5+jTKn21n83x4syc2uxG7MkiYg3waAOKGmm/G0PJvo5O9nV0sq/Dr8+xecClwkBfizh7R7v95ekvva8zS/uMoDNzIbBwVw3cXRGxtFW+aW+VvtrP0adV+mo/tadqVODfSr8b9nV0sq+jk30dOWq5NNFKYGbV64OBVf3lKZcKTwbW7uLYWsqUJEmSJKmmwPUu4PCImBUR7RQXW1rcK89i4Mxy+xTgh1msQV4MzC+vOjwLOBz4SY1lSpIkSZI08FLhzOyMiHOBJcBY4JrMvD8iLgKWZuZi4PPAlyJiOcVM6/zy2Psj4uvAA0An8L7M7ALoq8zGd29AQ7IEeYRqlb7az9GnVfpqP9XqWul3w76OTvZ1dLKvI8SAF2eSJEmSJKmZalkqLEmSJElS0xi4SpIkSZJGtJYNXCNiXkQsi4jlEXFhs9vTKBExMyJujYgHI+L+iHh/mb5fRNwUEb8un/dtdlsbISLGRsTPIuJ75etZEXFn2c/ryot/7fEiYkpEXB8Rvyzf29eNxvc0Is4rf2/vi4ivRUTHaHlPI+KaiHi6vO91Ja3P9zAK/1z+ffpFRLyqeS2vTz/9/Hj5u/uLiPhWREyp2reg7OeyiDixOa1Ws43WMRkcl0fL3/C+tMrYDI7Po2F8hj1/jG7JwDUixgJXAW8F5gCnRsSc5raqYTqBD2TmbwHHAu8r+3YhcEtmHg7cUr4eDd4PPFj1+jLgirKf64CzmtKqxrsS+I/MfCnwCoo+j6r3NCJmAH8BzM3Ml1FcuG0+o+c9vRaY1yutv/fwrRRXYT8cOAf4zDC1sRGu5YX9vAl4WWYeBfwKWABQ/m2aD/x2ecyny7/PaiGjfEwGx+XR8je8L6N+bAbHZ0bP+Ax7+BjdkoErcAywPDNXZOY2YBFwcpPb1BCZuTozf1puP0fxR3QGRf++UGb7AvCO5rSwcSLiYOD/A/61fB3Am4DryyyjpZ/7AG+guHo3mbktM59lFL6nFFc6nxDF/aAnAqsZJe9pZv4nxVXXq/X3Hp4MfDELdwBTImL68LR0cPrqZ2bemJmd5cs7KO7dDUU/F2Xm85n5MLCc4u+zWsuoHZPBcZlR8je8txYbm8HxeY8fn2HPH6NbNXCdATxe9XplmTaqRMShwCuBO4FpmbkaikEUOLB5LWuYTwJ/DXSXr/cHnq368I2W93U2sAb4t3L51b9GxF6Msvc0M58ALgceoxgQ1wN3Mzrf04r+3sPR/DfqT4AflNujuZ+qXcv8Hjguj6r3tiXGZnB8bqHxGUb4GN2qgWv0kTaq7gsUEZOAbwJ/mZkbmt2eRouItwFPZ+bd1cl9ZB0N72sb8CrgM5n5SmATo2DpUW/l+SMnA7OAg4C9KJbk9DYa3tOBjMrf5Yj4IMWyya9UkvrItsf3U3Vrid8Dx+UdRst72xJjMzg+9zJqf6f3hDG6VQPXlcDMqtcHA6ua1JaGi4hxFIPjVzLz38vkpypLGcrnp5vVvgb5XeCkiHiEYlnZmyi+6Z1SLmOB0fO+rgRWZuad5evrKQbL0faeHg88nJlrMnM78O/A7zA639OK/t7DUfc3KiLOBN4GnJY9NxAfdf3Ubhn1vweOy6Pyb3irjM3g+Dyqx2fYc8boVg1c7wIOL6+G1k5x4vHiJrepIcrzST4PPJiZ/1S1azFwZrl9JvCd4W5bI2Xmgsw8ODMPpXj/fpiZpwG3AqeU2fb4fgJk5pPA4xFxZJn0ZuABRtl7SrEE6diImFj+Hlf6Oere0yr9vYeLgTPKqxceC6yvLFnaE0XEPOAC4KTM3Fy1azEwPyLGR8Qsiotd/KQZbVRTjdoxGRyXGaV/w1tobAbH51E7PsMeNkZnZks+gP9BceWsh4APNrs9DezX71FM4/8CuKd8/A+K80xuAX5dPu/X7LY2sM/HAd8rt2dTfKiWA98Axje7fQ3q49HA0vJ9/Taw72h8T4G/A34J3Ad8CRg/Wt5T4GsU5wZtp/gW86z+3kOK5TlXlX+f7qW4kmPT+zCIfi6nOE+m8jfps1X5P1j2cxnw1ma330fTfm9G5Zhc9s1xeRT8De+nny0xNpd9dXzOPXt83kVf95gxOspGSZIkSZI0IrXqUmFJkiRJ0h7CwFWSJEmSNKIZuEqSJEmSRjQDV0mSJEnSiGbgKkmSJEka0QxcJUmSJEkjmoGr1CAR0RUR90TEzyPipxHxO2X6oRFxX4Prui0i5laV/+uIODEijouI9RHxs4hYFhH/GRFv6+P4n0fE13az7uMqfStf/2lEnLH7vZEkaWg4NkujR1uzGyCNIlsy82iAiDgRuAT4/aGsMCIOBpYAH8jMJRFxHPDjzHxbuf9o4NsRsSUzbynTfoviS6s3RMRembmpj3LbMrOzn2qPAzYC/xcgMz/b4G5JktQojs3SKOGMqzQ09gHW9U6MiPdExKeqXn+vHNCIiLdExO3lN8LfiIhJA9TxIuBG4EOZubivDJl5D3ARcG5V8ruBL5XHnlTVltsi4h8j4kfA+yPi7RFxZ/kN8c0RMS0iDgX+FDiv/Ab79RHx0Yg4vyzj6Ii4IyJ+ERHfioh9B+iDJEnDxbHZsVl7MANXqXEmlAPGL4F/Bf6+1gMj4gDgQ8DxmfkqYCnwVwMc9kXgU5n5jQHy/RR4adXrdwHXAV8DTu2Vd0pm/n5mfgL4L+DYzHwlsAj468x8BPgscEVmHp2ZP+6jTRdk5lHAvcDfDtA2SZKGkmOzY7NGCZcKS41TvRzpdcAXI+JlNR57LDAH+O+IAGgHbh/gmJuB0yPi2szcvIt8sWMj4jXAmsx8NCJWAtdExL6ZWfkG+rqq4w4GrouI6WV7Ht5VYyJiMsXg+qMy6QvAQAO3JElDybHZsVmjhDOu0hDIzNuBA4CpvXZ1svPnrqN8DuCm8pvSozNzTmaeNUA1HwPuBL4REbv6EuqVwIPl9qnASyPiEeAhimVTf1CVt/qcmn+h+Nb45cD/rmqrJEl7HMdmac9m4CoNgYh4KTAWeKbXrkeAoyNiTETMBI4p0+8AfjciXlIePzEijqihqvOADcDno/w6uFc7jgI+DFwVEWOAdwJHZeahmXkocDIvXJJUMRl4otw+syr9OWDv3pkzcz2wLiJeXyadDvyodz5JkprBsRlwbNYezKXCUuNMiIh7yu0AzszMrl5j1n9TLOu5F7iP4hwXMnNNRLwH+FpEjC/zfgj41a4qzMyMiDOB71F8y/t94PUR8TNgIvA08BeZeUt5oYknMvOJqiL+E5hTLjnq7aMU3xg/QTF4zyrTvwtcHxEnA3/e65gzgc9GxERgBfDHu2q/JElDzLHZsVmjRGRms9sgSZIkSVK/XCosSZIkSRrRXCosjWAR8S16lgFVXJCZS5rRHkmSWp1js9QcLhWWJEmSJI1oLhWWJEmSJI1oBq6SJEmSpBHNwFWSJEmSNKIZuEqSJEmSRrT/B8Z1Vhf2Xi3DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew:  6.8157\n",
      "Mean:  3.0369\n",
      "Standard Deviation:  2.6138\n"
     ]
    }
   ],
   "source": [
    "eds.plot_spread(X_train['Blue_KDAratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Blue_KillsTower</th>\n",
       "      <th>Blue_KillsInhib</th>\n",
       "      <th>Blue_KillsBaron</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>Purp_KillsTower</th>\n",
       "      <th>Purp_KillsInhib</th>\n",
       "      <th>Purp_KillsBaron</th>\n",
       "      <th>Blue_KDAratio</th>\n",
       "      <th>Blue_TtlGold</th>\n",
       "      <th>Purp_KDAratio</th>\n",
       "      <th>Purp_TtlGold</th>\n",
       "      <th>Diff_KillsTower</th>\n",
       "      <th>Diff_KillsInhib</th>\n",
       "      <th>Diff_TtlGold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>45171</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>13232</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>31939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Blue_FirstTower  Blue_FirstInhib  Blue_FirstDragon  Blue_FirstHerald  \\\n",
       "4705                1                1                 0                 0   \n",
       "\n",
       "      Blue_KillsTower  Blue_KillsInhib  Blue_KillsBaron  Purp_FirstInhib  \\\n",
       "4705                9                2                0                0   \n",
       "\n",
       "      Purp_FirstHerald  Purp_KillsTower  Purp_KillsInhib  Purp_KillsBaron  \\\n",
       "4705                 0                0                0                0   \n",
       "\n",
       "      Blue_KDAratio  Blue_TtlGold  Purp_KDAratio  Purp_TtlGold  \\\n",
       "4705          125.0         45171        0.03125         13232   \n",
       "\n",
       "      Diff_KillsTower  Diff_KillsInhib  Diff_TtlGold  \n",
       "4705                9                2         31939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue Won: 0\n"
     ]
    }
   ],
   "source": [
    "display(X_train.loc[X_train['Blue_KDAratio']>100])\n",
    "print('Blue Won:', y_train.iloc[4705])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew:  3.8394\n",
      "Mean:  3.0612\n",
      "Standard Deviation:  2.4081\n"
     ]
    }
   ],
   "source": [
    "eds.plot_spread(X_train['Purp_KDAratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Blue_KillsTower</th>\n",
       "      <th>Blue_KillsInhib</th>\n",
       "      <th>Blue_KillsBaron</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>Purp_KillsTower</th>\n",
       "      <th>Purp_KillsInhib</th>\n",
       "      <th>Purp_KillsBaron</th>\n",
       "      <th>Blue_KDAratio</th>\n",
       "      <th>Blue_TtlGold</th>\n",
       "      <th>Purp_KDAratio</th>\n",
       "      <th>Purp_TtlGold</th>\n",
       "      <th>Diff_KillsTower</th>\n",
       "      <th>Diff_KillsInhib</th>\n",
       "      <th>Diff_TtlGold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19581</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20582</td>\n",
       "      <td>60.0</td>\n",
       "      <td>37122</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-16540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>30974</td>\n",
       "      <td>62.0</td>\n",
       "      <td>47139</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-16165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Blue_FirstTower  Blue_FirstInhib  Blue_FirstDragon  Blue_FirstHerald  \\\n",
       "19581                0                0                 0                 0   \n",
       "16310                0                0                 1                 0   \n",
       "\n",
       "       Blue_KillsTower  Blue_KillsInhib  Blue_KillsBaron  Purp_FirstInhib  \\\n",
       "19581                0                0                0                1   \n",
       "16310                0                0                0                1   \n",
       "\n",
       "       Purp_FirstHerald  Purp_KillsTower  Purp_KillsInhib  Purp_KillsBaron  \\\n",
       "19581                 1                8                1                0   \n",
       "16310                 1                8                1                1   \n",
       "\n",
       "       Blue_KDAratio  Blue_TtlGold  Purp_KDAratio  Purp_TtlGold  \\\n",
       "19581       0.000000         20582           60.0         37122   \n",
       "16310       0.136364         30974           62.0         47139   \n",
       "\n",
       "       Diff_KillsTower  Diff_KillsInhib  Diff_TtlGold  \n",
       "19581               -8               -1        -16540  \n",
       "16310               -8               -1        -16165  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue Won: 0\n",
      "Blue Won: 0\n"
     ]
    }
   ],
   "source": [
    "display(X_train.loc[X_train['Purp_KDAratio']>58])\n",
    "for i in y_train.iloc[[16310, 19581]]:\n",
    "    print('Blue Won:', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Since we are not using a linear model, we shouldn't be too much concerned with the outliers but the one in the Blue_KDAratio has caught my attention. Even though it is the highest KDA ratio for a team in the whole training set, the team (Blue) hasn't won that match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train values trimmed:  1\n",
      "CV values trimmed:  0\n",
      "Test values trimmed:  0\n"
     ]
    }
   ],
   "source": [
    "train_lght, cv_lght, test_lght = X_train.shape[0], X_cv.shape[0], X_test.shape[0]\n",
    "\n",
    "X_train = X_train.loc[X_train['Blue_KDAratio']<80]\n",
    "X_train = X_train.loc[X_train['Purp_KDAratio']<80]\n",
    "y_train = y_train.drop([i for i in y_train.index if i not in X_train.index])\n",
    "\n",
    "X_cv = X_cv.loc[X_cv['Blue_KDAratio']<80]\n",
    "X_cv = X_cv.loc[X_cv['Purp_KDAratio']<80]\n",
    "y_cv = y_cv.drop([i for i in y_cv.index if i not in X_cv.index])\n",
    "\n",
    "X_test = X_test.loc[X_test['Blue_KDAratio']<80]\n",
    "X_test = X_test.loc[X_test['Purp_KDAratio']<80]\n",
    "y_test = y_test.drop([i for i in y_test.index if i not in X_test.index])\n",
    "\n",
    "print('Train values trimmed: ', train_lght - X_train.shape[0])\n",
    "print('CV values trimmed: ', cv_lght - X_cv.shape[0])\n",
    "print('Test values trimmed: ', test_lght - X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;*NOTE*: This is in one game that happened to be sampled in the train set when I made this part of the notebook and I forgot that I am going to distort it by rerunning it. Feel free to change the code so it displays the value in the respective dataset where it is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'colsample_bytree': [0.5, 0.7, 0.9, 1],\n",
       "                          'min_samples_leaf': [1, 3, 5],\n",
       "                          'n_estimators': [10, 20, 40, 100, 200, 400],\n",
       "                          'n_jobs': [-1]}],\n",
       "             pre_dispatch='2*n_jobs', refit='r2', return_train_score=True,\n",
       "             scoring=['r2', 'accuracy'], verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "params = [\n",
    "    {'n_estimators': [10, 20, 40, 100, 200, 400], 'min_samples_leaf': [1, 3, 5],\n",
    "     'colsample_bytree': [0.5, 0.7, 0.9, 1], 'n_jobs': [-1]}\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(xgb, params, scoring=['r2', 'accuracy'], return_train_score=True,\n",
    "                    cv=3, refit='r2')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Grid 2 hyperparams: max_depth, jeff heathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 200,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'colsample_bytree': [0.4, 0.5, 0.6],\n",
       "                          'max_depth': [5, 10, 15, 19], 'min_samples_leaf': [1],\n",
       "                          'n_estimators': [100], 'n_jobs': [-1]}],\n",
       "             pre_dispatch='2*n_jobs', refit='r2', return_train_score=True,\n",
       "             scoring=['r2', 'accuracy'], verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [\n",
    "    {'n_estimators': [100], 'min_samples_leaf': [1], 'max_depth':[5, 10, 15, 19],\n",
    "     'colsample_bytree': [0.4, 0.5, 0.6], 'n_jobs': [-1]}\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(xgb, params, scoring=['r2', 'accuracy'], return_train_score=True,\n",
    "                    cv=3, refit='r2')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB test:\n",
      "[0.977718, 0.994437]\n",
      "\n",
      "LR test:\n",
      "[0.936869, 0.984237]\n",
      "\n",
      "(r2 and accuracy)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=100, max_depth=5, colsample_bytree=0.4,\n",
    "                    min_samples_leaf=1, n_jobs=-1)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "def get_scores(model, X, y):\n",
    "    r2 = round(r2_score(y, model.predict(X)), 6)\n",
    "    acc = round(accuracy_score(y, model.predict(X)), 6)\n",
    "    print([r2, acc])\n",
    "\n",
    "print('XGB test:')\n",
    "get_scores(xgb, X_test, y_test)\n",
    "\n",
    "print('\\nLR test:')\n",
    "get_scores(lr, X_test, y_test)\n",
    "\n",
    "print('\\n(r2 and accuracy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR scaled cv:\n",
      "[0.943888, 0.985976]\n",
      "\n",
      "LR scaled test:\n",
      "[0.95358, 0.98841]\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_cv_scaled, X_test_scaled = ss.transform(X_cv), ss.transform(X_test)\n",
    "\n",
    "lrs = LogisticRegression()\n",
    "lrs.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('LR scaled cv:')\n",
    "get_scores(lrs, X_cv_scaled, y_cv)\n",
    "\n",
    "print('\\nLR scaled test:')\n",
    "get_scores(lrs, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;We can scale the data for a slight accuracy boost or we can leave it as it is if we want to preserve the interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample\n",
    "&emsp;The real test now begins. We are going to look at how our features and predictions behave like in a real game. The reason I kept logistic regression is that its initial 50%/50% win probabilities (as you would expect) held true and the pre-testing I did on the random forest seemed to bias for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features at the start of a game:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Blue_KillsTower</th>\n",
       "      <th>Blue_KillsInhib</th>\n",
       "      <th>Blue_KillsBaron</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>Purp_KillsTower</th>\n",
       "      <th>Purp_KillsInhib</th>\n",
       "      <th>Purp_KillsBaron</th>\n",
       "      <th>Blue_KDAratio</th>\n",
       "      <th>Blue_TtlGold</th>\n",
       "      <th>Purp_KDAratio</th>\n",
       "      <th>Purp_TtlGold</th>\n",
       "      <th>Diff_KillsTower</th>\n",
       "      <th>Diff_KillsInhib</th>\n",
       "      <th>Diff_TtlGold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue_FirstTower  Blue_FirstInhib  Blue_FirstDragon  Blue_FirstHerald  \\\n",
       "0                0                0                 0                 0   \n",
       "\n",
       "   Blue_KillsTower  Blue_KillsInhib  Blue_KillsBaron  Purp_FirstInhib  \\\n",
       "0                0                0                0                0   \n",
       "\n",
       "   Purp_FirstHerald  Purp_KillsTower  Purp_KillsInhib  Purp_KillsBaron  \\\n",
       "0                 0                0                0                0   \n",
       "\n",
       "   Blue_KDAratio  Blue_TtlGold  Purp_KDAratio  Purp_TtlGold  Diff_KillsTower  \\\n",
       "0              0          2500              0          2500                0   \n",
       "\n",
       "   Diff_KillsInhib  Diff_TtlGold  \n",
       "0                0             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Probabilities at game start:\n",
      "---------------------\n",
      "XGB:\n",
      "0: 0.1371\n",
      "1: 0.8629\n",
      "\n",
      "LR:\n",
      "0: 0.4991\n",
      "1: 0.5009\n"
     ]
    }
   ],
   "source": [
    "def class_probs(ftrs, model):\n",
    "    for team, proba in zip(model.classes_, model.predict_proba(ftrs)[0]):\n",
    "        print(str(team)+':', round(proba, 4))\n",
    "        \n",
    "game_start = pd.DataFrame(np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2500, \n",
    "                                     0, 2500, 0, 0, 0]]), columns=X_train.columns)\n",
    "print('Features at the start of a game:')\n",
    "display(game_start)\n",
    "\n",
    "print('---------------------\\nProbabilities at game start:\\n---------------------')\n",
    "print('XGB:')\n",
    "class_probs(game_start.iloc[:1], xgb)\n",
    "print('\\nLR:')\n",
    "class_probs(game_start.iloc[:1], lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_game = pd.read_csv('sample_game.csv')\n",
    "\n",
    "sample_game['XGB_1'] = pd.DataFrame(xgb.predict_proba(sample_game.iloc[:, 1:20]))[1]\n",
    "sample_game['XGB_0'] = pd.DataFrame(xgb.predict_proba(sample_game.iloc[:, 1:20]))[0]\n",
    "sample_game['LR_1'] = pd.DataFrame(lr.predict_proba(sample_game.iloc[:, 1:20]))[1]\n",
    "sample_game['LR_0'] = pd.DataFrame(lr.predict_proba(sample_game.iloc[:, 1:20]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minute</th>\n",
       "      <th>Blue_FirstTower</th>\n",
       "      <th>Blue_FirstInhib</th>\n",
       "      <th>Blue_FirstDragon</th>\n",
       "      <th>Blue_FirstHerald</th>\n",
       "      <th>Blue_KillsTower</th>\n",
       "      <th>Blue_KillsInhib</th>\n",
       "      <th>Blue_KillsBaron</th>\n",
       "      <th>Purp_FirstInhib</th>\n",
       "      <th>Purp_FirstHerald</th>\n",
       "      <th>...</th>\n",
       "      <th>Blue_TtlGold</th>\n",
       "      <th>Purp_KDAratio</th>\n",
       "      <th>Purp_TtlGold</th>\n",
       "      <th>Diff_KillsTower</th>\n",
       "      <th>Diff_KillsInhib</th>\n",
       "      <th>Diff_TtlGold</th>\n",
       "      <th>XGB_1</th>\n",
       "      <th>XGB_0</th>\n",
       "      <th>LR_1</th>\n",
       "      <th>LR_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795397</td>\n",
       "      <td>0.204603</td>\n",
       "      <td>0.499298</td>\n",
       "      <td>0.500702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795397</td>\n",
       "      <td>0.204603</td>\n",
       "      <td>0.499487</td>\n",
       "      <td>0.500513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.795397</td>\n",
       "      <td>0.204603</td>\n",
       "      <td>0.515526</td>\n",
       "      <td>0.484474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.557704</td>\n",
       "      <td>0.442296</td>\n",
       "      <td>0.485513</td>\n",
       "      <td>0.514487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7400</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>0.557704</td>\n",
       "      <td>0.442296</td>\n",
       "      <td>0.470558</td>\n",
       "      <td>0.529442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0.557704</td>\n",
       "      <td>0.442296</td>\n",
       "      <td>0.455805</td>\n",
       "      <td>0.544195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>0.540523</td>\n",
       "      <td>0.459477</td>\n",
       "      <td>0.381223</td>\n",
       "      <td>0.618777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0.517234</td>\n",
       "      <td>0.482766</td>\n",
       "      <td>0.396401</td>\n",
       "      <td>0.603599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12900</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1300</td>\n",
       "      <td>0.636030</td>\n",
       "      <td>0.363970</td>\n",
       "      <td>0.312904</td>\n",
       "      <td>0.687096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13800</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2000</td>\n",
       "      <td>0.050160</td>\n",
       "      <td>0.949840</td>\n",
       "      <td>0.219297</td>\n",
       "      <td>0.780703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15700</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1800</td>\n",
       "      <td>0.041970</td>\n",
       "      <td>0.958030</td>\n",
       "      <td>0.244938</td>\n",
       "      <td>0.755062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17400</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1400</td>\n",
       "      <td>0.800028</td>\n",
       "      <td>0.199972</td>\n",
       "      <td>0.303068</td>\n",
       "      <td>0.696932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18800</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>21400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2600</td>\n",
       "      <td>0.041760</td>\n",
       "      <td>0.958240</td>\n",
       "      <td>0.163260</td>\n",
       "      <td>0.836740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19900</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3100</td>\n",
       "      <td>0.035807</td>\n",
       "      <td>0.964193</td>\n",
       "      <td>0.125507</td>\n",
       "      <td>0.874493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22300</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>24600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2300</td>\n",
       "      <td>0.083568</td>\n",
       "      <td>0.916432</td>\n",
       "      <td>0.197077</td>\n",
       "      <td>0.802923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23700</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>27800</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4100</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.992604</td>\n",
       "      <td>0.047831</td>\n",
       "      <td>0.952169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>29300</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3300</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>0.992971</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.922176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27400</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>31300</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3900</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.996073</td>\n",
       "      <td>0.054274</td>\n",
       "      <td>0.945726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30200</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>34300</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-4100</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>0.979127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32200</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>35600</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3400</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.993775</td>\n",
       "      <td>0.031895</td>\n",
       "      <td>0.968105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33800</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>37100</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3300</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.992844</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.966063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35100</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40700</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-5600</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.991892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36200</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42600</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-6400</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.998321</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.995029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38000</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>46100</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>-8100</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.999134</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.999293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40900</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>48200</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>-7300</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.995944</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.998820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42400</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>50400</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>-8000</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.996563</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.999226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44500</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>51600</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>-7100</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.995380</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.998633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46100</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>53700</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>-7600</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.996097</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.998994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47700</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>56600</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>-8900</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.996403</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.999550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Minute  Blue_FirstTower  Blue_FirstInhib  Blue_FirstDragon  \\\n",
       "0        1              0.5                0               0.5   \n",
       "1        2              0.5                0               0.5   \n",
       "2        3              0.5                0               0.5   \n",
       "3        4              0.5                0               0.5   \n",
       "4        5              0.5                0               0.5   \n",
       "5        6              0.5                0               0.5   \n",
       "6        7              0.5                0               0.5   \n",
       "7        8              0.5                0               0.5   \n",
       "8        9              0.5                0               1.0   \n",
       "9       10              0.5                0               1.0   \n",
       "10      11              0.5                0               1.0   \n",
       "11      12              0.5                0               1.0   \n",
       "12      13              0.5                0               1.0   \n",
       "13      14              0.5                0               1.0   \n",
       "14      15              0.5                0               1.0   \n",
       "15      16              0.0                0               1.0   \n",
       "16      17              0.0                0               1.0   \n",
       "17      18              0.0                0               1.0   \n",
       "18      19              0.0                0               1.0   \n",
       "19      20              0.0                0               1.0   \n",
       "20      21              0.0                0               1.0   \n",
       "21      22              0.0                0               1.0   \n",
       "22      23              0.0                0               1.0   \n",
       "23      24              0.0                0               1.0   \n",
       "24      25              0.0                0               1.0   \n",
       "25      26              0.0                0               1.0   \n",
       "26      27              0.0                0               1.0   \n",
       "27      28              0.0                0               1.0   \n",
       "28      29              0.0                0               1.0   \n",
       "\n",
       "    Blue_FirstHerald  Blue_KillsTower  Blue_KillsInhib  Blue_KillsBaron  \\\n",
       "0                  0                0                0                0   \n",
       "1                  0                0                0                0   \n",
       "2                  0                0                0                0   \n",
       "3                  0                0                0                0   \n",
       "4                  0                0                0                0   \n",
       "5                  0                0                0                0   \n",
       "6                  0                0                0                0   \n",
       "7                  0                0                0                0   \n",
       "8                  0                0                0                0   \n",
       "9                  0                0                0                0   \n",
       "10                 0                0                0                0   \n",
       "11                 0                0                0                0   \n",
       "12                 0                0                0                0   \n",
       "13                 0                0                0                0   \n",
       "14                 0                0                0                0   \n",
       "15                 0                0                0                0   \n",
       "16                 0                0                0                0   \n",
       "17                 0                0                0                0   \n",
       "18                 0                0                0                0   \n",
       "19                 0                0                0                0   \n",
       "20                 0                0                0                0   \n",
       "21                 0                0                0                0   \n",
       "22                 0                0                0                0   \n",
       "23                 0                0                0                0   \n",
       "24                 0                0                0                0   \n",
       "25                 0                1                0                0   \n",
       "26                 0                1                0                0   \n",
       "27                 0                1                0                0   \n",
       "28                 0                1                0                0   \n",
       "\n",
       "    Purp_FirstInhib  Purp_FirstHerald  ...  Blue_TtlGold  Purp_KDAratio  \\\n",
       "0                 0                 0  ...          2500       0.000000   \n",
       "1                 0                 0  ...          3000       0.000000   \n",
       "2                 0                 0  ...          4600       0.000000   \n",
       "3                 0                 0  ...          6200       2.000000   \n",
       "4                 0                 0  ...          7400       2.000000   \n",
       "5                 0                 0  ...          9000       2.000000   \n",
       "6                 0                 0  ...         10100       2.000000   \n",
       "7                 0                 0  ...         11500       2.000000   \n",
       "8                 0                 0  ...         12900       2.000000   \n",
       "9                 0                 0  ...         13800       3.000000   \n",
       "10                0                 0  ...         15700       3.000000   \n",
       "11                0                 0  ...         17400       2.000000   \n",
       "12                0                 0  ...         18800       3.666667   \n",
       "13                0                 0  ...         19900       3.666667   \n",
       "14                0                 0  ...         22300       2.400000   \n",
       "15                0                 0  ...         23700       3.400000   \n",
       "16                0                 0  ...         26000       2.833333   \n",
       "17                0                 0  ...         27400       3.166667   \n",
       "18                0                 0  ...         30200       2.777778   \n",
       "19                0                 0  ...         32200       2.777778   \n",
       "20                0                 0  ...         33800       2.777778   \n",
       "21                0                 0  ...         35100       4.000000   \n",
       "22                0                 0  ...         36200       4.000000   \n",
       "23                0                 0  ...         38000       4.416667   \n",
       "24                0                 0  ...         40900       3.928571   \n",
       "25                0                 0  ...         42400       3.928571   \n",
       "26                0                 0  ...         44500       3.666667   \n",
       "27                0                 0  ...         46100       3.750000   \n",
       "28                0                 0  ...         47700       3.823529   \n",
       "\n",
       "    Purp_TtlGold  Diff_KillsTower  Diff_KillsInhib  Diff_TtlGold     XGB_1  \\\n",
       "0           2500                0                0             0  0.795397   \n",
       "1           3000                0                0             0  0.795397   \n",
       "2           4500                0                0           100  0.795397   \n",
       "3           6300                0                0          -100  0.557704   \n",
       "4           7600                0                0          -200  0.557704   \n",
       "5           9300                0                0          -300  0.557704   \n",
       "6          10900                0                0          -800  0.540523   \n",
       "7          12200                0                0          -700  0.517234   \n",
       "8          14200                0                0         -1300  0.636030   \n",
       "9          15800                0                0         -2000  0.050160   \n",
       "10         17500                0                0         -1800  0.041970   \n",
       "11         18800                0                0         -1400  0.800028   \n",
       "12         21400                0                0         -2600  0.041760   \n",
       "13         23000                0                0         -3100  0.035807   \n",
       "14         24600                0                0         -2300  0.083568   \n",
       "15         27800               -1                0         -4100  0.007395   \n",
       "16         29300               -1                0         -3300  0.007029   \n",
       "17         31300               -1                0         -3900  0.003927   \n",
       "18         34300               -3                0         -4100  0.003936   \n",
       "19         35600               -3                0         -3400  0.006225   \n",
       "20         37100               -3                0         -3300  0.007156   \n",
       "21         40700               -3                0         -5600  0.002532   \n",
       "22         42600               -3                0         -6400  0.001679   \n",
       "23         46100               -5                0         -8100  0.000866   \n",
       "24         48200               -5                0         -7300  0.004056   \n",
       "25         50400               -5                0         -8000  0.003437   \n",
       "26         51600               -5                0         -7100  0.004620   \n",
       "27         53700               -5                0         -7600  0.003903   \n",
       "28         56600               -5                0         -8900  0.003597   \n",
       "\n",
       "       XGB_0      LR_1      LR_0  \n",
       "0   0.204603  0.499298  0.500702  \n",
       "1   0.204603  0.499487  0.500513  \n",
       "2   0.204603  0.515526  0.484474  \n",
       "3   0.442296  0.485513  0.514487  \n",
       "4   0.442296  0.470558  0.529442  \n",
       "5   0.442296  0.455805  0.544195  \n",
       "6   0.459477  0.381223  0.618777  \n",
       "7   0.482766  0.396401  0.603599  \n",
       "8   0.363970  0.312904  0.687096  \n",
       "9   0.949840  0.219297  0.780703  \n",
       "10  0.958030  0.244938  0.755062  \n",
       "11  0.199972  0.303068  0.696932  \n",
       "12  0.958240  0.163260  0.836740  \n",
       "13  0.964193  0.125507  0.874493  \n",
       "14  0.916432  0.197077  0.802923  \n",
       "15  0.992604  0.047831  0.952169  \n",
       "16  0.992971  0.077824  0.922176  \n",
       "17  0.996073  0.054274  0.945726  \n",
       "18  0.996064  0.020873  0.979127  \n",
       "19  0.993775  0.031895  0.968105  \n",
       "20  0.992844  0.033937  0.966063  \n",
       "21  0.997468  0.008108  0.991892  \n",
       "22  0.998321  0.004971  0.995029  \n",
       "23  0.999134  0.000707  0.999293  \n",
       "24  0.995944  0.001180  0.998820  \n",
       "25  0.996563  0.000774  0.999226  \n",
       "26  0.995380  0.001367  0.998633  \n",
       "27  0.996097  0.001006  0.998994  \n",
       "28  0.996403  0.000450  0.999550  \n",
       "\n",
       "[29 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Even though XGBoost might have better overall scores on the test data, it failed the actual test it is meant to be used for. I could go further to investigate why is that the case but in the end, the feature space has only 19 columns where XGBoost would be an overkill, especially because our objective isn't clearly defined. I also planned to use Logistic regression up to some point in the game and then transition to the XGBoost because it is more accurate but as I said, it is an overkill.\n",
    "<br><br>\n",
    "This sample/demo might have not been enough so I did the more detailed one in the next section of the project, accompanied by a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lr, 'logistic_regression.pkl')\n",
    "joblib.dump(lrs, 'scaled_logistic_regression.pkl');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
